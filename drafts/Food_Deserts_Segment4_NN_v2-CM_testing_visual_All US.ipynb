{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UTMCC DataViz Module 20 Team Project --  \n",
    "## Neural Network Machine Deep Learning Model  \n",
    "### Food Deserts in the Austin, Texas Metro Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import activations\n",
    "# Import checkpoint dependencies\n",
    "import os\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "import datetime as dt\n",
    "import calendar\n",
    "import random\n",
    "from path import Path\n",
    "import itertools\n",
    "# import io\n",
    "# import sys\n",
    "# import psycopg2\n",
    "# import csv\n",
    "# import codecs\n",
    "# import boto3\n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib import style\n",
    "style.use('fivethirtyeight')\n",
    "import matplotlib.pyplot as plt\n",
    "# import statistics\n",
    "# from flask import Flask, jsonify\n",
    "# from mpl_toolkits.mplot3d import Axes3D\n",
    "# from hvplot import hvPlot\n",
    "# import hvplot.pandas\n",
    "# import plotly.express as px\n",
    "\n",
    "# Python SQL toolkit and Object Relational Mapper\n",
    "import sqlite3\n",
    "import sqlalchemy\n",
    "from sqlalchemy.ext.automap import automap_base\n",
    "from sqlalchemy.orm import Session\n",
    "from sqlalchemy import create_engine, func, select, delete, Table\n",
    "from sqlalchemy import extract\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import and read csv file from AWS S3 Bucket using Boto 3 and Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Download csv file from AWS S3 and create a pandas dataframe \n",
    "\n",
    "# client = boto3.client('s3', 'us-east-2', aws_access_key_id='xxxxxxxx', \n",
    "#                                   aws_secret_access_key='xxxxxxxxy')\n",
    "\n",
    "# obj = client.get_object(Bucket= \"dataviz20-bucket\", Key= \"food_access_research_atlas.csv\") \n",
    "\n",
    "# food_atlas_df = pd.read_csv(io.BytesIO(obj['Body'].read()), encoding='utf8')\n",
    "# food_atlas_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# client = boto3.client('s3', 'us-east-2', aws_access_key_id='xxxxxxxx', \n",
    "#                                   aws_secret_access_key='xxxxxxxxy')\n",
    "\n",
    "# obj = client.get_object(Bucket= \"dataviz20-bucket\", Key= \"food_desert_austin_censustract.csv\") \n",
    "\n",
    "# fooddesert_austin_censustract_df = pd.read_csv(io.BytesIO(obj['Body'].read()), encoding='utf8')\n",
    "# # fooddesert_austin_censustract_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# client = boto3.client('s3', 'us-east-2', aws_access_key_id='xxxxxxxx', \n",
    "#                                   aws_secret_access_key='xxxxxxxxy')\n",
    "\n",
    "# obj = client.get_object(Bucket= \"dataviz20-bucket\", Key= \"census_tract_shapefiles_all.csv\") \n",
    "\n",
    "# census_tract_shapefiles_all_df = pd.read_csv(io.BytesIO(obj['Body'].read()), encoding='utf8')\n",
    "# # census_tract_shapefiles_all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Rename column GEOID to CensusTract\n",
    "# census_tract_shapefiles_all_df = census_tract_shapefiles_all_df.rename(columns={\"GEOID\":\"CensusTract\"})\n",
    "# # census_tract_shapefiles_all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and read csv files\n",
    "food_atlas_df = pd.read_csv(\"resources/food_access_research_atlas.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#food_atlas_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CensusTract       int64\n",
       "State            object\n",
       "County           object\n",
       "Urban             int64\n",
       "POP2010           int64\n",
       "                  ...  \n",
       "TractAIAN         int64\n",
       "TractOMultir      int64\n",
       "TractHispanic     int64\n",
       "TractHUNV         int64\n",
       "TractSNAP         int64\n",
       "Length: 147, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "food_atlas_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CensusTract</th>\n",
       "      <th>State</th>\n",
       "      <th>County</th>\n",
       "      <th>Urban</th>\n",
       "      <th>POP2010</th>\n",
       "      <th>OHU2010</th>\n",
       "      <th>GroupQuartersFlag</th>\n",
       "      <th>NUMGQTRS</th>\n",
       "      <th>PCTGQTRS</th>\n",
       "      <th>LILATracts_1And10</th>\n",
       "      <th>...</th>\n",
       "      <th>TractSeniors</th>\n",
       "      <th>TractWhite</th>\n",
       "      <th>TractBlack</th>\n",
       "      <th>TractAsian</th>\n",
       "      <th>TractNHOPI</th>\n",
       "      <th>TractAIAN</th>\n",
       "      <th>TractOMultir</th>\n",
       "      <th>TractHispanic</th>\n",
       "      <th>TractHUNV</th>\n",
       "      <th>TractSNAP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72859</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72860</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72861</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72862</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72863</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72864 rows × 147 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       CensusTract  State  County  Urban  POP2010  OHU2010  GroupQuartersFlag  \\\n",
       "0            False  False   False  False    False    False              False   \n",
       "1            False  False   False  False    False    False              False   \n",
       "2            False  False   False  False    False    False              False   \n",
       "3            False  False   False  False    False    False              False   \n",
       "4            False  False   False  False    False    False              False   \n",
       "...            ...    ...     ...    ...      ...      ...                ...   \n",
       "72859        False  False   False  False    False    False              False   \n",
       "72860        False  False   False  False    False    False              False   \n",
       "72861        False  False   False  False    False    False              False   \n",
       "72862        False  False   False  False    False    False              False   \n",
       "72863        False  False   False  False    False    False              False   \n",
       "\n",
       "       NUMGQTRS  PCTGQTRS  LILATracts_1And10  ...  TractSeniors  TractWhite  \\\n",
       "0         False     False              False  ...         False       False   \n",
       "1         False     False              False  ...         False       False   \n",
       "2         False     False              False  ...         False       False   \n",
       "3         False     False              False  ...         False       False   \n",
       "4         False     False              False  ...         False       False   \n",
       "...         ...       ...                ...  ...           ...         ...   \n",
       "72859     False     False              False  ...         False       False   \n",
       "72860     False     False              False  ...         False       False   \n",
       "72861     False     False              False  ...         False       False   \n",
       "72862     False     False              False  ...         False       False   \n",
       "72863     False     False              False  ...         False       False   \n",
       "\n",
       "       TractBlack  TractAsian  TractNHOPI  TractAIAN  TractOMultir  \\\n",
       "0           False       False       False      False         False   \n",
       "1           False       False       False      False         False   \n",
       "2           False       False       False      False         False   \n",
       "3           False       False       False      False         False   \n",
       "4           False       False       False      False         False   \n",
       "...           ...         ...         ...        ...           ...   \n",
       "72859       False       False       False      False         False   \n",
       "72860       False       False       False      False         False   \n",
       "72861       False       False       False      False         False   \n",
       "72862       False       False       False      False         False   \n",
       "72863       False       False       False      False         False   \n",
       "\n",
       "       TractHispanic  TractHUNV  TractSNAP  \n",
       "0              False      False      False  \n",
       "1              False      False      False  \n",
       "2              False      False      False  \n",
       "3              False      False      False  \n",
       "4              False      False      False  \n",
       "...              ...        ...        ...  \n",
       "72859          False      False      False  \n",
       "72860          False      False      False  \n",
       "72861          False      False      False  \n",
       "72862          False      False      False  \n",
       "72863          False      False      False  \n",
       "\n",
       "[72864 rows x 147 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for missing values using isnull()\n",
    "food_atlas_df.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CensusTract</th>\n",
       "      <th>State</th>\n",
       "      <th>County</th>\n",
       "      <th>Urban</th>\n",
       "      <th>POP2010</th>\n",
       "      <th>OHU2010</th>\n",
       "      <th>GroupQuartersFlag</th>\n",
       "      <th>NUMGQTRS</th>\n",
       "      <th>PCTGQTRS</th>\n",
       "      <th>LILATracts_1And10</th>\n",
       "      <th>...</th>\n",
       "      <th>TractSeniors</th>\n",
       "      <th>TractWhite</th>\n",
       "      <th>TractBlack</th>\n",
       "      <th>TractAsian</th>\n",
       "      <th>TractNHOPI</th>\n",
       "      <th>TractAIAN</th>\n",
       "      <th>TractOMultir</th>\n",
       "      <th>TractHispanic</th>\n",
       "      <th>TractHUNV</th>\n",
       "      <th>TractSNAP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001020100</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Autauga</td>\n",
       "      <td>1</td>\n",
       "      <td>1912</td>\n",
       "      <td>693</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>221</td>\n",
       "      <td>1622</td>\n",
       "      <td>217</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>45</td>\n",
       "      <td>44</td>\n",
       "      <td>26</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1001020200</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Autauga</td>\n",
       "      <td>1</td>\n",
       "      <td>2170</td>\n",
       "      <td>743</td>\n",
       "      <td>0</td>\n",
       "      <td>181</td>\n",
       "      <td>0.083410</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>214</td>\n",
       "      <td>888</td>\n",
       "      <td>1217</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>55</td>\n",
       "      <td>75</td>\n",
       "      <td>87</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1001020300</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Autauga</td>\n",
       "      <td>1</td>\n",
       "      <td>3373</td>\n",
       "      <td>1256</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>439</td>\n",
       "      <td>2576</td>\n",
       "      <td>647</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>117</td>\n",
       "      <td>87</td>\n",
       "      <td>108</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1001020400</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Autauga</td>\n",
       "      <td>1</td>\n",
       "      <td>4386</td>\n",
       "      <td>1722</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>904</td>\n",
       "      <td>4086</td>\n",
       "      <td>193</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>74</td>\n",
       "      <td>85</td>\n",
       "      <td>19</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1001020500</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Autauga</td>\n",
       "      <td>1</td>\n",
       "      <td>10766</td>\n",
       "      <td>4082</td>\n",
       "      <td>0</td>\n",
       "      <td>181</td>\n",
       "      <td>0.016812</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1126</td>\n",
       "      <td>8666</td>\n",
       "      <td>1437</td>\n",
       "      <td>296</td>\n",
       "      <td>9</td>\n",
       "      <td>48</td>\n",
       "      <td>310</td>\n",
       "      <td>355</td>\n",
       "      <td>198</td>\n",
       "      <td>488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72859</th>\n",
       "      <td>56043000200</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>Washakie</td>\n",
       "      <td>0</td>\n",
       "      <td>3326</td>\n",
       "      <td>1317</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>0.017138</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>593</td>\n",
       "      <td>3106</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>172</td>\n",
       "      <td>309</td>\n",
       "      <td>56</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72860</th>\n",
       "      <td>56043000301</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>Washakie</td>\n",
       "      <td>1</td>\n",
       "      <td>2665</td>\n",
       "      <td>1154</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.003752</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>399</td>\n",
       "      <td>2377</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>220</td>\n",
       "      <td>446</td>\n",
       "      <td>114</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72861</th>\n",
       "      <td>56043000302</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>Washakie</td>\n",
       "      <td>1</td>\n",
       "      <td>2542</td>\n",
       "      <td>1021</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>0.028717</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>516</td>\n",
       "      <td>2312</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>182</td>\n",
       "      <td>407</td>\n",
       "      <td>82</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72862</th>\n",
       "      <td>56045951100</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>Weston</td>\n",
       "      <td>0</td>\n",
       "      <td>3314</td>\n",
       "      <td>1322</td>\n",
       "      <td>0</td>\n",
       "      <td>252</td>\n",
       "      <td>0.076041</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>499</td>\n",
       "      <td>3179</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>62</td>\n",
       "      <td>91</td>\n",
       "      <td>108</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72863</th>\n",
       "      <td>56045951300</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>Weston</td>\n",
       "      <td>1</td>\n",
       "      <td>3894</td>\n",
       "      <td>1699</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>0.015665</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>650</td>\n",
       "      <td>3706</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "      <td>126</td>\n",
       "      <td>125</td>\n",
       "      <td>95</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72864 rows × 147 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       CensusTract    State    County  Urban  POP2010  OHU2010  \\\n",
       "0       1001020100  Alabama   Autauga      1     1912      693   \n",
       "1       1001020200  Alabama   Autauga      1     2170      743   \n",
       "2       1001020300  Alabama   Autauga      1     3373     1256   \n",
       "3       1001020400  Alabama   Autauga      1     4386     1722   \n",
       "4       1001020500  Alabama   Autauga      1    10766     4082   \n",
       "...            ...      ...       ...    ...      ...      ...   \n",
       "72859  56043000200  Wyoming  Washakie      0     3326     1317   \n",
       "72860  56043000301  Wyoming  Washakie      1     2665     1154   \n",
       "72861  56043000302  Wyoming  Washakie      1     2542     1021   \n",
       "72862  56045951100  Wyoming    Weston      0     3314     1322   \n",
       "72863  56045951300  Wyoming    Weston      1     3894     1699   \n",
       "\n",
       "       GroupQuartersFlag  NUMGQTRS  PCTGQTRS  LILATracts_1And10  ...  \\\n",
       "0                      0         0  0.000000                  0  ...   \n",
       "1                      0       181  0.083410                  0  ...   \n",
       "2                      0         0  0.000000                  0  ...   \n",
       "3                      0         0  0.000000                  0  ...   \n",
       "4                      0       181  0.016812                  0  ...   \n",
       "...                  ...       ...       ...                ...  ...   \n",
       "72859                  0        57  0.017138                  0  ...   \n",
       "72860                  0        10  0.003752                  0  ...   \n",
       "72861                  0        73  0.028717                  0  ...   \n",
       "72862                  0       252  0.076041                  0  ...   \n",
       "72863                  0        61  0.015665                  0  ...   \n",
       "\n",
       "       TractSeniors  TractWhite  TractBlack  TractAsian  TractNHOPI  \\\n",
       "0               221        1622         217          14           0   \n",
       "1               214         888        1217           5           0   \n",
       "2               439        2576         647          17           5   \n",
       "3               904        4086         193          18           4   \n",
       "4              1126        8666        1437         296           9   \n",
       "...             ...         ...         ...         ...         ...   \n",
       "72859           593        3106           6          15           0   \n",
       "72860           399        2377           5          23           0   \n",
       "72861           516        2312          11          10           1   \n",
       "72862           499        3179          15          10           1   \n",
       "72863           650        3706           6          10           2   \n",
       "\n",
       "       TractAIAN  TractOMultir  TractHispanic  TractHUNV  TractSNAP  \n",
       "0             14            45             44         26        112  \n",
       "1              5            55             75         87        202  \n",
       "2             11           117             87        108        120  \n",
       "3             11            74             85         19         82  \n",
       "4             48           310            355        198        488  \n",
       "...          ...           ...            ...        ...        ...  \n",
       "72859         27           172            309         56        116  \n",
       "72860         40           220            446        114        124  \n",
       "72861         26           182            407         82         97  \n",
       "72862         47            62             91        108         50  \n",
       "72863         44           126            125         95        168  \n",
       "\n",
       "[72864 rows x 147 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop rows that may have null, missing values.\n",
    "rows_len_nan_check = food_atlas_df.dropna(how='all')\n",
    "rows_len_nan_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old data frame length: 72864\n",
      "New data frame length: 72864\n",
      "Number of rows with at least 1 NA value:  0\n"
     ]
    }
   ],
   "source": [
    "# Compare sizes of the dataframes to indicate how many rows had a minimum of one null value. \n",
    "print(\"Old data frame length:\", len(food_atlas_df)) \n",
    "print(\"New data frame length:\", len(rows_len_nan_check))  \n",
    "print(\"Number of rows with at least 1 NA value: \", (len(food_atlas_df)-len(rows_len_nan_check))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CensusTract</th>\n",
       "      <th>State</th>\n",
       "      <th>County</th>\n",
       "      <th>Urban</th>\n",
       "      <th>POP2010</th>\n",
       "      <th>OHU2010</th>\n",
       "      <th>GroupQuartersFlag</th>\n",
       "      <th>NUMGQTRS</th>\n",
       "      <th>PCTGQTRS</th>\n",
       "      <th>LILATracts_1And10</th>\n",
       "      <th>...</th>\n",
       "      <th>TractSeniors</th>\n",
       "      <th>TractWhite</th>\n",
       "      <th>TractBlack</th>\n",
       "      <th>TractAsian</th>\n",
       "      <th>TractNHOPI</th>\n",
       "      <th>TractAIAN</th>\n",
       "      <th>TractOMultir</th>\n",
       "      <th>TractHispanic</th>\n",
       "      <th>TractHUNV</th>\n",
       "      <th>TractSNAP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61468</th>\n",
       "      <td>48001950100</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Anderson</td>\n",
       "      <td>0</td>\n",
       "      <td>4685</td>\n",
       "      <td>1874</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>0.010459</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>912</td>\n",
       "      <td>4012</td>\n",
       "      <td>452</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>186</td>\n",
       "      <td>236</td>\n",
       "      <td>125</td>\n",
       "      <td>218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61469</th>\n",
       "      <td>48001950401</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Anderson</td>\n",
       "      <td>0</td>\n",
       "      <td>5422</td>\n",
       "      <td>77</td>\n",
       "      <td>1</td>\n",
       "      <td>5219</td>\n",
       "      <td>0.962560</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>24</td>\n",
       "      <td>1825</td>\n",
       "      <td>2266</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1305</td>\n",
       "      <td>1324</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61470</th>\n",
       "      <td>48001950402</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Anderson</td>\n",
       "      <td>0</td>\n",
       "      <td>7535</td>\n",
       "      <td>83</td>\n",
       "      <td>1</td>\n",
       "      <td>7315</td>\n",
       "      <td>0.970803</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>134</td>\n",
       "      <td>2591</td>\n",
       "      <td>3248</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1673</td>\n",
       "      <td>1737</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61471</th>\n",
       "      <td>48001950500</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Anderson</td>\n",
       "      <td>1</td>\n",
       "      <td>4377</td>\n",
       "      <td>1604</td>\n",
       "      <td>0</td>\n",
       "      <td>86</td>\n",
       "      <td>0.019648</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>627</td>\n",
       "      <td>2737</td>\n",
       "      <td>800</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>799</td>\n",
       "      <td>1389</td>\n",
       "      <td>66</td>\n",
       "      <td>288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61472</th>\n",
       "      <td>48001950600</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Anderson</td>\n",
       "      <td>1</td>\n",
       "      <td>6405</td>\n",
       "      <td>2253</td>\n",
       "      <td>0</td>\n",
       "      <td>96</td>\n",
       "      <td>0.014988</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>791</td>\n",
       "      <td>3831</td>\n",
       "      <td>1674</td>\n",
       "      <td>68</td>\n",
       "      <td>4</td>\n",
       "      <td>43</td>\n",
       "      <td>785</td>\n",
       "      <td>1253</td>\n",
       "      <td>194</td>\n",
       "      <td>412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66721</th>\n",
       "      <td>48505950400</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Zapata</td>\n",
       "      <td>0</td>\n",
       "      <td>5610</td>\n",
       "      <td>1741</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>555</td>\n",
       "      <td>5264</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>299</td>\n",
       "      <td>5176</td>\n",
       "      <td>58</td>\n",
       "      <td>539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66722</th>\n",
       "      <td>48507950100</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Zavala</td>\n",
       "      <td>0</td>\n",
       "      <td>1232</td>\n",
       "      <td>388</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>125</td>\n",
       "      <td>1056</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>170</td>\n",
       "      <td>1104</td>\n",
       "      <td>55</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66723</th>\n",
       "      <td>48507950200</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Zavala</td>\n",
       "      <td>0</td>\n",
       "      <td>1880</td>\n",
       "      <td>590</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>203</td>\n",
       "      <td>1612</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>223</td>\n",
       "      <td>1635</td>\n",
       "      <td>59</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66724</th>\n",
       "      <td>48507950301</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Zavala</td>\n",
       "      <td>0</td>\n",
       "      <td>2254</td>\n",
       "      <td>628</td>\n",
       "      <td>0</td>\n",
       "      <td>348</td>\n",
       "      <td>0.154392</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>225</td>\n",
       "      <td>2096</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>140</td>\n",
       "      <td>2109</td>\n",
       "      <td>160</td>\n",
       "      <td>384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66725</th>\n",
       "      <td>48507950302</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Zavala</td>\n",
       "      <td>1</td>\n",
       "      <td>6311</td>\n",
       "      <td>1967</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>0.009666</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>855</td>\n",
       "      <td>5537</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>23</td>\n",
       "      <td>693</td>\n",
       "      <td>6113</td>\n",
       "      <td>310</td>\n",
       "      <td>616</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5258 rows × 147 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       CensusTract  State    County  Urban  POP2010  OHU2010  \\\n",
       "61468  48001950100  Texas  Anderson      0     4685     1874   \n",
       "61469  48001950401  Texas  Anderson      0     5422       77   \n",
       "61470  48001950402  Texas  Anderson      0     7535       83   \n",
       "61471  48001950500  Texas  Anderson      1     4377     1604   \n",
       "61472  48001950600  Texas  Anderson      1     6405     2253   \n",
       "...            ...    ...       ...    ...      ...      ...   \n",
       "66721  48505950400  Texas    Zapata      0     5610     1741   \n",
       "66722  48507950100  Texas    Zavala      0     1232      388   \n",
       "66723  48507950200  Texas    Zavala      0     1880      590   \n",
       "66724  48507950301  Texas    Zavala      0     2254      628   \n",
       "66725  48507950302  Texas    Zavala      1     6311     1967   \n",
       "\n",
       "       GroupQuartersFlag  NUMGQTRS  PCTGQTRS  LILATracts_1And10  ...  \\\n",
       "61468                  0        49  0.010459                  0  ...   \n",
       "61469                  1      5219  0.962560                  0  ...   \n",
       "61470                  1      7315  0.970803                  0  ...   \n",
       "61471                  0        86  0.019648                  1  ...   \n",
       "61472                  0        96  0.014988                  1  ...   \n",
       "...                  ...       ...       ...                ...  ...   \n",
       "66721                  0         0  0.000000                  1  ...   \n",
       "66722                  0         0  0.000000                  1  ...   \n",
       "66723                  0         0  0.000000                  1  ...   \n",
       "66724                  0       348  0.154392                  0  ...   \n",
       "66725                  0        61  0.009666                  1  ...   \n",
       "\n",
       "       TractSeniors  TractWhite  TractBlack  TractAsian  TractNHOPI  \\\n",
       "61468           912        4012         452          22           0   \n",
       "61469            24        1825        2266          21           0   \n",
       "61470           134        2591        3248          13           0   \n",
       "61471           627        2737         800          19           2   \n",
       "61472           791        3831        1674          68           4   \n",
       "...             ...         ...         ...         ...         ...   \n",
       "66721           555        5264           5          12           0   \n",
       "66722           125        1056           4           0           0   \n",
       "66723           203        1612          21           2           9   \n",
       "66724           225        2096          14           1           0   \n",
       "66725           855        5537          50           1           7   \n",
       "\n",
       "       TractAIAN  TractOMultir  TractHispanic  TractHUNV  TractSNAP  \n",
       "61468         13           186            236        125        218  \n",
       "61469          5          1305           1324          5          0  \n",
       "61470         10          1673           1737          0          0  \n",
       "61471         20           799           1389         66        288  \n",
       "61472         43           785           1253        194        412  \n",
       "...          ...           ...            ...        ...        ...  \n",
       "66721         30           299           5176         58        539  \n",
       "66722          2           170           1104         55        164  \n",
       "66723         13           223           1635         59        155  \n",
       "66724          3           140           2109        160        384  \n",
       "66725         23           693           6113        310        616  \n",
       "\n",
       "[5258 rows x 147 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create new df keeping only Texas\n",
    "food_texas_df = food_atlas_df[(food_atlas_df[\"State\"]==\"Texas\")]\n",
    "food_texas_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CensusTract</th>\n",
       "      <th>State</th>\n",
       "      <th>County</th>\n",
       "      <th>Urban</th>\n",
       "      <th>POP2010</th>\n",
       "      <th>OHU2010</th>\n",
       "      <th>GroupQuartersFlag</th>\n",
       "      <th>NUMGQTRS</th>\n",
       "      <th>PCTGQTRS</th>\n",
       "      <th>LILATracts_1And10</th>\n",
       "      <th>...</th>\n",
       "      <th>TractSeniors</th>\n",
       "      <th>TractWhite</th>\n",
       "      <th>TractBlack</th>\n",
       "      <th>TractAsian</th>\n",
       "      <th>TractNHOPI</th>\n",
       "      <th>TractAIAN</th>\n",
       "      <th>TractOMultir</th>\n",
       "      <th>TractHispanic</th>\n",
       "      <th>TractHUNV</th>\n",
       "      <th>TractSNAP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61529</th>\n",
       "      <td>48021950100</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Bastrop</td>\n",
       "      <td>0</td>\n",
       "      <td>8608</td>\n",
       "      <td>3063</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1028</td>\n",
       "      <td>6507</td>\n",
       "      <td>383</td>\n",
       "      <td>53</td>\n",
       "      <td>4</td>\n",
       "      <td>65</td>\n",
       "      <td>1596</td>\n",
       "      <td>2660</td>\n",
       "      <td>51</td>\n",
       "      <td>351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61530</th>\n",
       "      <td>48021950200</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Bastrop</td>\n",
       "      <td>1</td>\n",
       "      <td>7955</td>\n",
       "      <td>2625</td>\n",
       "      <td>0</td>\n",
       "      <td>186</td>\n",
       "      <td>0.023381</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>891</td>\n",
       "      <td>4521</td>\n",
       "      <td>1328</td>\n",
       "      <td>32</td>\n",
       "      <td>14</td>\n",
       "      <td>76</td>\n",
       "      <td>1984</td>\n",
       "      <td>3674</td>\n",
       "      <td>148</td>\n",
       "      <td>444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61531</th>\n",
       "      <td>48021950300</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Bastrop</td>\n",
       "      <td>0</td>\n",
       "      <td>12927</td>\n",
       "      <td>4734</td>\n",
       "      <td>0</td>\n",
       "      <td>71</td>\n",
       "      <td>0.005492</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1468</td>\n",
       "      <td>9971</td>\n",
       "      <td>1213</td>\n",
       "      <td>156</td>\n",
       "      <td>18</td>\n",
       "      <td>88</td>\n",
       "      <td>1481</td>\n",
       "      <td>3012</td>\n",
       "      <td>95</td>\n",
       "      <td>568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61532</th>\n",
       "      <td>48021950400</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Bastrop</td>\n",
       "      <td>1</td>\n",
       "      <td>7984</td>\n",
       "      <td>3127</td>\n",
       "      <td>0</td>\n",
       "      <td>456</td>\n",
       "      <td>0.057114</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1199</td>\n",
       "      <td>6312</td>\n",
       "      <td>800</td>\n",
       "      <td>78</td>\n",
       "      <td>3</td>\n",
       "      <td>62</td>\n",
       "      <td>729</td>\n",
       "      <td>1711</td>\n",
       "      <td>255</td>\n",
       "      <td>261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61533</th>\n",
       "      <td>48021950501</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Bastrop</td>\n",
       "      <td>0</td>\n",
       "      <td>8008</td>\n",
       "      <td>2168</td>\n",
       "      <td>0</td>\n",
       "      <td>1519</td>\n",
       "      <td>0.189685</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>566</td>\n",
       "      <td>5209</td>\n",
       "      <td>849</td>\n",
       "      <td>37</td>\n",
       "      <td>12</td>\n",
       "      <td>123</td>\n",
       "      <td>1778</td>\n",
       "      <td>3253</td>\n",
       "      <td>128</td>\n",
       "      <td>285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66673</th>\n",
       "      <td>48491021507</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Williamson</td>\n",
       "      <td>1</td>\n",
       "      <td>9196</td>\n",
       "      <td>3293</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>444</td>\n",
       "      <td>6315</td>\n",
       "      <td>1227</td>\n",
       "      <td>421</td>\n",
       "      <td>15</td>\n",
       "      <td>44</td>\n",
       "      <td>1174</td>\n",
       "      <td>2710</td>\n",
       "      <td>179</td>\n",
       "      <td>277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66674</th>\n",
       "      <td>48491021508</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Williamson</td>\n",
       "      <td>1</td>\n",
       "      <td>6531</td>\n",
       "      <td>2402</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>301</td>\n",
       "      <td>4744</td>\n",
       "      <td>761</td>\n",
       "      <td>303</td>\n",
       "      <td>7</td>\n",
       "      <td>28</td>\n",
       "      <td>688</td>\n",
       "      <td>1627</td>\n",
       "      <td>23</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66675</th>\n",
       "      <td>48491021601</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Williamson</td>\n",
       "      <td>0</td>\n",
       "      <td>3278</td>\n",
       "      <td>1120</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>236</td>\n",
       "      <td>2569</td>\n",
       "      <td>102</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>567</td>\n",
       "      <td>954</td>\n",
       "      <td>5</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66676</th>\n",
       "      <td>48491021602</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Williamson</td>\n",
       "      <td>0</td>\n",
       "      <td>2857</td>\n",
       "      <td>959</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>332</td>\n",
       "      <td>2464</td>\n",
       "      <td>47</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>311</td>\n",
       "      <td>906</td>\n",
       "      <td>12</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66677</th>\n",
       "      <td>48491021603</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Williamson</td>\n",
       "      <td>0</td>\n",
       "      <td>1653</td>\n",
       "      <td>540</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>181</td>\n",
       "      <td>1393</td>\n",
       "      <td>19</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>216</td>\n",
       "      <td>532</td>\n",
       "      <td>14</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>350 rows × 147 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       CensusTract  State      County  Urban  POP2010  OHU2010  \\\n",
       "61529  48021950100  Texas     Bastrop      0     8608     3063   \n",
       "61530  48021950200  Texas     Bastrop      1     7955     2625   \n",
       "61531  48021950300  Texas     Bastrop      0    12927     4734   \n",
       "61532  48021950400  Texas     Bastrop      1     7984     3127   \n",
       "61533  48021950501  Texas     Bastrop      0     8008     2168   \n",
       "...            ...    ...         ...    ...      ...      ...   \n",
       "66673  48491021507  Texas  Williamson      1     9196     3293   \n",
       "66674  48491021508  Texas  Williamson      1     6531     2402   \n",
       "66675  48491021601  Texas  Williamson      0     3278     1120   \n",
       "66676  48491021602  Texas  Williamson      0     2857      959   \n",
       "66677  48491021603  Texas  Williamson      0     1653      540   \n",
       "\n",
       "       GroupQuartersFlag  NUMGQTRS  PCTGQTRS  LILATracts_1And10  ...  \\\n",
       "61529                  0         0  0.000000                  0  ...   \n",
       "61530                  0       186  0.023381                  1  ...   \n",
       "61531                  0        71  0.005492                  0  ...   \n",
       "61532                  0       456  0.057114                  0  ...   \n",
       "61533                  0      1519  0.189685                  0  ...   \n",
       "...                  ...       ...       ...                ...  ...   \n",
       "66673                  0         1  0.000109                  0  ...   \n",
       "66674                  0         0  0.000000                  0  ...   \n",
       "66675                  0         0  0.000000                  1  ...   \n",
       "66676                  0         0  0.000000                  0  ...   \n",
       "66677                  0         0  0.000000                  1  ...   \n",
       "\n",
       "       TractSeniors  TractWhite  TractBlack  TractAsian  TractNHOPI  \\\n",
       "61529          1028        6507         383          53           4   \n",
       "61530           891        4521        1328          32          14   \n",
       "61531          1468        9971        1213         156          18   \n",
       "61532          1199        6312         800          78           3   \n",
       "61533           566        5209         849          37          12   \n",
       "...             ...         ...         ...         ...         ...   \n",
       "66673           444        6315        1227         421          15   \n",
       "66674           301        4744         761         303           7   \n",
       "66675           236        2569         102          19           6   \n",
       "66676           332        2464          47          19           0   \n",
       "66677           181        1393          19          13           0   \n",
       "\n",
       "       TractAIAN  TractOMultir  TractHispanic  TractHUNV  TractSNAP  \n",
       "61529         65          1596           2660         51        351  \n",
       "61530         76          1984           3674        148        444  \n",
       "61531         88          1481           3012         95        568  \n",
       "61532         62           729           1711        255        261  \n",
       "61533        123          1778           3253        128        285  \n",
       "...          ...           ...            ...        ...        ...  \n",
       "66673         44          1174           2710        179        277  \n",
       "66674         28           688           1627         23        133  \n",
       "66675         15           567            954          5         26  \n",
       "66676         16           311            906         12        106  \n",
       "66677         12           216            532         14         31  \n",
       "\n",
       "[350 rows x 147 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create new df keeping only select Counties in the Austin Metro Area\n",
    "counties = [\"Bastrop\", \"Caldwell\", \"Hays\", \"Travis\", \"Williamson\"]\n",
    "food_austin_df = food_texas_df.loc[food_texas_df[\"County\"].isin(counties)]\n",
    "food_austin_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CensusTract</th>\n",
       "      <th>LILATracts_1And10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61529</th>\n",
       "      <td>48021950100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61530</th>\n",
       "      <td>48021950200</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61531</th>\n",
       "      <td>48021950300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61532</th>\n",
       "      <td>48021950400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61533</th>\n",
       "      <td>48021950501</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66673</th>\n",
       "      <td>48491021507</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66674</th>\n",
       "      <td>48491021508</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66675</th>\n",
       "      <td>48491021601</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66676</th>\n",
       "      <td>48491021602</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66677</th>\n",
       "      <td>48491021603</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>350 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       CensusTract  LILATracts_1And10\n",
       "61529  48021950100                  0\n",
       "61530  48021950200                  1\n",
       "61531  48021950300                  0\n",
       "61532  48021950400                  0\n",
       "61533  48021950501                  0\n",
       "...            ...                ...\n",
       "66673  48491021507                  0\n",
       "66674  48491021508                  0\n",
       "66675  48491021601                  1\n",
       "66676  48491021602                  0\n",
       "66677  48491021603                  1\n",
       "\n",
       "[350 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a file for visualization, food desert tracts for Austin Metro Area  food_austin_df.loc\n",
    "# aus_desert_tracts = [\"CensusTract\", \"LILATracts_1And10\"]\n",
    "LILATracts_1And10_aus_df = food_austin_df[[\"CensusTract\", \"LILATracts_1And10\"]]\n",
    "LILATracts_1And10_aus_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export to csv \n",
    "# LILATracts_1And10_aus_df.to_csv(\"LILATracts_1And10_aus.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61529    70516\n",
       "61530    67792\n",
       "61531    75462\n",
       "61532    62375\n",
       "61533    65079\n",
       "         ...  \n",
       "66673    66820\n",
       "66674    83241\n",
       "66675    57389\n",
       "66676    63125\n",
       "66677    58902\n",
       "Name: MedianFamilyIncome, Length: 350, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Begin Income column creation (target variable), MFI = MedianFamilyIncome']\n",
    "food_austinMFI_df = food_austin_df\n",
    "food_austinMFI_df['MedianFamilyIncome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CensusTract</th>\n",
       "      <th>State</th>\n",
       "      <th>County</th>\n",
       "      <th>Urban</th>\n",
       "      <th>POP2010</th>\n",
       "      <th>OHU2010</th>\n",
       "      <th>GroupQuartersFlag</th>\n",
       "      <th>NUMGQTRS</th>\n",
       "      <th>PCTGQTRS</th>\n",
       "      <th>LILATracts_1And10</th>\n",
       "      <th>...</th>\n",
       "      <th>TractWhite</th>\n",
       "      <th>TractBlack</th>\n",
       "      <th>TractAsian</th>\n",
       "      <th>TractNHOPI</th>\n",
       "      <th>TractAIAN</th>\n",
       "      <th>TractOMultir</th>\n",
       "      <th>TractHispanic</th>\n",
       "      <th>TractHUNV</th>\n",
       "      <th>TractSNAP</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61529</th>\n",
       "      <td>48021950100</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Bastrop</td>\n",
       "      <td>0</td>\n",
       "      <td>8608</td>\n",
       "      <td>3063</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6507</td>\n",
       "      <td>383</td>\n",
       "      <td>53</td>\n",
       "      <td>4</td>\n",
       "      <td>65</td>\n",
       "      <td>1596</td>\n",
       "      <td>2660</td>\n",
       "      <td>51</td>\n",
       "      <td>351</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61530</th>\n",
       "      <td>48021950200</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Bastrop</td>\n",
       "      <td>1</td>\n",
       "      <td>7955</td>\n",
       "      <td>2625</td>\n",
       "      <td>0</td>\n",
       "      <td>186</td>\n",
       "      <td>0.023381</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4521</td>\n",
       "      <td>1328</td>\n",
       "      <td>32</td>\n",
       "      <td>14</td>\n",
       "      <td>76</td>\n",
       "      <td>1984</td>\n",
       "      <td>3674</td>\n",
       "      <td>148</td>\n",
       "      <td>444</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61531</th>\n",
       "      <td>48021950300</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Bastrop</td>\n",
       "      <td>0</td>\n",
       "      <td>12927</td>\n",
       "      <td>4734</td>\n",
       "      <td>0</td>\n",
       "      <td>71</td>\n",
       "      <td>0.005492</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>9971</td>\n",
       "      <td>1213</td>\n",
       "      <td>156</td>\n",
       "      <td>18</td>\n",
       "      <td>88</td>\n",
       "      <td>1481</td>\n",
       "      <td>3012</td>\n",
       "      <td>95</td>\n",
       "      <td>568</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61532</th>\n",
       "      <td>48021950400</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Bastrop</td>\n",
       "      <td>1</td>\n",
       "      <td>7984</td>\n",
       "      <td>3127</td>\n",
       "      <td>0</td>\n",
       "      <td>456</td>\n",
       "      <td>0.057114</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6312</td>\n",
       "      <td>800</td>\n",
       "      <td>78</td>\n",
       "      <td>3</td>\n",
       "      <td>62</td>\n",
       "      <td>729</td>\n",
       "      <td>1711</td>\n",
       "      <td>255</td>\n",
       "      <td>261</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61533</th>\n",
       "      <td>48021950501</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Bastrop</td>\n",
       "      <td>0</td>\n",
       "      <td>8008</td>\n",
       "      <td>2168</td>\n",
       "      <td>0</td>\n",
       "      <td>1519</td>\n",
       "      <td>0.189685</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5209</td>\n",
       "      <td>849</td>\n",
       "      <td>37</td>\n",
       "      <td>12</td>\n",
       "      <td>123</td>\n",
       "      <td>1778</td>\n",
       "      <td>3253</td>\n",
       "      <td>128</td>\n",
       "      <td>285</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 148 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       CensusTract  State   County  Urban  POP2010  OHU2010  \\\n",
       "61529  48021950100  Texas  Bastrop      0     8608     3063   \n",
       "61530  48021950200  Texas  Bastrop      1     7955     2625   \n",
       "61531  48021950300  Texas  Bastrop      0    12927     4734   \n",
       "61532  48021950400  Texas  Bastrop      1     7984     3127   \n",
       "61533  48021950501  Texas  Bastrop      0     8008     2168   \n",
       "\n",
       "       GroupQuartersFlag  NUMGQTRS  PCTGQTRS  LILATracts_1And10  ...  \\\n",
       "61529                  0         0  0.000000                  0  ...   \n",
       "61530                  0       186  0.023381                  1  ...   \n",
       "61531                  0        71  0.005492                  0  ...   \n",
       "61532                  0       456  0.057114                  0  ...   \n",
       "61533                  0      1519  0.189685                  0  ...   \n",
       "\n",
       "       TractWhite  TractBlack  TractAsian  TractNHOPI  TractAIAN  \\\n",
       "61529        6507         383          53           4         65   \n",
       "61530        4521        1328          32          14         76   \n",
       "61531        9971        1213         156          18         88   \n",
       "61532        6312         800          78           3         62   \n",
       "61533        5209         849          37          12        123   \n",
       "\n",
       "       TractOMultir  TractHispanic  TractHUNV  TractSNAP  Income  \n",
       "61529          1596           2660         51        351       1  \n",
       "61530          1984           3674        148        444       1  \n",
       "61531          1481           3012         95        568       1  \n",
       "61532           729           1711        255        261       1  \n",
       "61533          1778           3253        128        285       1  \n",
       "\n",
       "[5 rows x 148 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Poverty Guidelines U.S. 2015 family of 4 is $24250\n",
    "conditions = [(food_austinMFI_df['MedianFamilyIncome'] <= 24250), \n",
    "              (food_austinMFI_df['MedianFamilyIncome'] > 24250)]\n",
    "values = [0, 1]\n",
    "food_austinMFI_df[\"Income\"] = np.select(conditions, values)\n",
    "food_austinMFI_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CensusTract       int64\n",
       "State            object\n",
       "County           object\n",
       "Urban             int64\n",
       "POP2010           int64\n",
       "                  ...  \n",
       "TractOMultir      int64\n",
       "TractHispanic     int64\n",
       "TractHUNV         int64\n",
       "TractSNAP         int64\n",
       "Income            int32\n",
       "Length: 148, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "food_austinMFI_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export to csv \n",
    "# food_austinMFI_df.to_csv(\"food_desert_austinMFI.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Income</th>\n",
       "      <th>lasnaphalfshare</th>\n",
       "      <th>lahunvhalfshare</th>\n",
       "      <th>lasnap1share</th>\n",
       "      <th>lahunv1share</th>\n",
       "      <th>lasnap10share</th>\n",
       "      <th>lahunv10share</th>\n",
       "      <th>lasnap20share</th>\n",
       "      <th>lahunv20share</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61529</th>\n",
       "      <td>1</td>\n",
       "      <td>0.106149</td>\n",
       "      <td>0.015850</td>\n",
       "      <td>0.104443</td>\n",
       "      <td>0.015635</td>\n",
       "      <td>0.001684</td>\n",
       "      <td>0.000301</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61530</th>\n",
       "      <td>1</td>\n",
       "      <td>0.140413</td>\n",
       "      <td>0.045970</td>\n",
       "      <td>0.088953</td>\n",
       "      <td>0.031108</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61531</th>\n",
       "      <td>1</td>\n",
       "      <td>0.124636</td>\n",
       "      <td>0.021290</td>\n",
       "      <td>0.116085</td>\n",
       "      <td>0.017944</td>\n",
       "      <td>0.010261</td>\n",
       "      <td>0.001849</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61532</th>\n",
       "      <td>1</td>\n",
       "      <td>0.077106</td>\n",
       "      <td>0.061340</td>\n",
       "      <td>0.060436</td>\n",
       "      <td>0.036602</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61533</th>\n",
       "      <td>1</td>\n",
       "      <td>0.141932</td>\n",
       "      <td>0.066633</td>\n",
       "      <td>0.141930</td>\n",
       "      <td>0.066632</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66673</th>\n",
       "      <td>1</td>\n",
       "      <td>0.076911</td>\n",
       "      <td>0.044745</td>\n",
       "      <td>0.060783</td>\n",
       "      <td>0.028574</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66674</th>\n",
       "      <td>1</td>\n",
       "      <td>0.027253</td>\n",
       "      <td>0.001319</td>\n",
       "      <td>0.015606</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66675</th>\n",
       "      <td>1</td>\n",
       "      <td>0.022260</td>\n",
       "      <td>0.005910</td>\n",
       "      <td>0.022260</td>\n",
       "      <td>0.005910</td>\n",
       "      <td>0.013610</td>\n",
       "      <td>0.002004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66676</th>\n",
       "      <td>1</td>\n",
       "      <td>0.108607</td>\n",
       "      <td>0.013994</td>\n",
       "      <td>0.108607</td>\n",
       "      <td>0.013994</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66677</th>\n",
       "      <td>1</td>\n",
       "      <td>0.060311</td>\n",
       "      <td>0.028938</td>\n",
       "      <td>0.060311</td>\n",
       "      <td>0.028938</td>\n",
       "      <td>0.021407</td>\n",
       "      <td>0.006965</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>350 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Income  lasnaphalfshare  lahunvhalfshare  lasnap1share  lahunv1share  \\\n",
       "61529       1         0.106149         0.015850      0.104443      0.015635   \n",
       "61530       1         0.140413         0.045970      0.088953      0.031108   \n",
       "61531       1         0.124636         0.021290      0.116085      0.017944   \n",
       "61532       1         0.077106         0.061340      0.060436      0.036602   \n",
       "61533       1         0.141932         0.066633      0.141930      0.066632   \n",
       "...       ...              ...              ...           ...           ...   \n",
       "66673       1         0.076911         0.044745      0.060783      0.028574   \n",
       "66674       1         0.027253         0.001319      0.015606      0.000144   \n",
       "66675       1         0.022260         0.005910      0.022260      0.005910   \n",
       "66676       1         0.108607         0.013994      0.108607      0.013994   \n",
       "66677       1         0.060311         0.028938      0.060311      0.028938   \n",
       "\n",
       "       lasnap10share  lahunv10share  lasnap20share  lahunv20share  \n",
       "61529       0.001684       0.000301            0.0            0.0  \n",
       "61530       0.000000       0.000000            0.0            0.0  \n",
       "61531       0.010261       0.001849            0.0            0.0  \n",
       "61532       0.000000       0.000000            0.0            0.0  \n",
       "61533       0.000000       0.000000            0.0            0.0  \n",
       "...              ...            ...            ...            ...  \n",
       "66673       0.000000       0.000000            0.0            0.0  \n",
       "66674       0.000000       0.000000            0.0            0.0  \n",
       "66675       0.013610       0.002004            0.0            0.0  \n",
       "66676       0.000000       0.000000            0.0            0.0  \n",
       "66677       0.021407       0.006965            0.0            0.0  \n",
       "\n",
       "[350 rows x 9 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create new df with select feature columns representing \"share\" values\n",
    "food_desert_Austin_df = food_austinMFI_df[[\"Income\", \"lasnaphalfshare\", \"lahunvhalfshare\", \"lasnap1share\", \"lahunv1share\", \"lasnap10share\", \"lahunv10share\", \"lasnap20share\", \"lahunv20share\"]]\n",
    "food_desert_Austin_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export to csv \n",
    "# food_desert_Austin_df.to_csv(\"food_desert_Austin.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing for: ML Training on full U.S. Census dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        74750\n",
       "1        51875\n",
       "2        52905\n",
       "3        68079\n",
       "4        77819\n",
       "         ...  \n",
       "72859    67917\n",
       "72860    52474\n",
       "72861    66250\n",
       "72862    81500\n",
       "72863    68966\n",
       "Name: MedianFamilyIncome, Length: 72864, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Preparation for full U.S. dataset\n",
    "# Begin Income column creation (target variable), MFI = MedianFamilyIncome\n",
    "food_atlasMFI_df = food_atlas_df\n",
    "food_atlasMFI_df['MedianFamilyIncome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CensusTract</th>\n",
       "      <th>State</th>\n",
       "      <th>County</th>\n",
       "      <th>Urban</th>\n",
       "      <th>POP2010</th>\n",
       "      <th>OHU2010</th>\n",
       "      <th>GroupQuartersFlag</th>\n",
       "      <th>NUMGQTRS</th>\n",
       "      <th>PCTGQTRS</th>\n",
       "      <th>LILATracts_1And10</th>\n",
       "      <th>...</th>\n",
       "      <th>TractWhite</th>\n",
       "      <th>TractBlack</th>\n",
       "      <th>TractAsian</th>\n",
       "      <th>TractNHOPI</th>\n",
       "      <th>TractAIAN</th>\n",
       "      <th>TractOMultir</th>\n",
       "      <th>TractHispanic</th>\n",
       "      <th>TractHUNV</th>\n",
       "      <th>TractSNAP</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001020100</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Autauga</td>\n",
       "      <td>1</td>\n",
       "      <td>1912</td>\n",
       "      <td>693</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1622</td>\n",
       "      <td>217</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>45</td>\n",
       "      <td>44</td>\n",
       "      <td>26</td>\n",
       "      <td>112</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1001020200</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Autauga</td>\n",
       "      <td>1</td>\n",
       "      <td>2170</td>\n",
       "      <td>743</td>\n",
       "      <td>0</td>\n",
       "      <td>181</td>\n",
       "      <td>0.083410</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>888</td>\n",
       "      <td>1217</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>55</td>\n",
       "      <td>75</td>\n",
       "      <td>87</td>\n",
       "      <td>202</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1001020300</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Autauga</td>\n",
       "      <td>1</td>\n",
       "      <td>3373</td>\n",
       "      <td>1256</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2576</td>\n",
       "      <td>647</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>117</td>\n",
       "      <td>87</td>\n",
       "      <td>108</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1001020400</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Autauga</td>\n",
       "      <td>1</td>\n",
       "      <td>4386</td>\n",
       "      <td>1722</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4086</td>\n",
       "      <td>193</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>74</td>\n",
       "      <td>85</td>\n",
       "      <td>19</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1001020500</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Autauga</td>\n",
       "      <td>1</td>\n",
       "      <td>10766</td>\n",
       "      <td>4082</td>\n",
       "      <td>0</td>\n",
       "      <td>181</td>\n",
       "      <td>0.016812</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8666</td>\n",
       "      <td>1437</td>\n",
       "      <td>296</td>\n",
       "      <td>9</td>\n",
       "      <td>48</td>\n",
       "      <td>310</td>\n",
       "      <td>355</td>\n",
       "      <td>198</td>\n",
       "      <td>488</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72859</th>\n",
       "      <td>56043000200</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>Washakie</td>\n",
       "      <td>0</td>\n",
       "      <td>3326</td>\n",
       "      <td>1317</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>0.017138</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3106</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>172</td>\n",
       "      <td>309</td>\n",
       "      <td>56</td>\n",
       "      <td>116</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72860</th>\n",
       "      <td>56043000301</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>Washakie</td>\n",
       "      <td>1</td>\n",
       "      <td>2665</td>\n",
       "      <td>1154</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.003752</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2377</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>220</td>\n",
       "      <td>446</td>\n",
       "      <td>114</td>\n",
       "      <td>124</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72861</th>\n",
       "      <td>56043000302</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>Washakie</td>\n",
       "      <td>1</td>\n",
       "      <td>2542</td>\n",
       "      <td>1021</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>0.028717</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2312</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>182</td>\n",
       "      <td>407</td>\n",
       "      <td>82</td>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72862</th>\n",
       "      <td>56045951100</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>Weston</td>\n",
       "      <td>0</td>\n",
       "      <td>3314</td>\n",
       "      <td>1322</td>\n",
       "      <td>0</td>\n",
       "      <td>252</td>\n",
       "      <td>0.076041</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3179</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>62</td>\n",
       "      <td>91</td>\n",
       "      <td>108</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72863</th>\n",
       "      <td>56045951300</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>Weston</td>\n",
       "      <td>1</td>\n",
       "      <td>3894</td>\n",
       "      <td>1699</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>0.015665</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3706</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "      <td>126</td>\n",
       "      <td>125</td>\n",
       "      <td>95</td>\n",
       "      <td>168</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72864 rows × 148 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       CensusTract    State    County  Urban  POP2010  OHU2010  \\\n",
       "0       1001020100  Alabama   Autauga      1     1912      693   \n",
       "1       1001020200  Alabama   Autauga      1     2170      743   \n",
       "2       1001020300  Alabama   Autauga      1     3373     1256   \n",
       "3       1001020400  Alabama   Autauga      1     4386     1722   \n",
       "4       1001020500  Alabama   Autauga      1    10766     4082   \n",
       "...            ...      ...       ...    ...      ...      ...   \n",
       "72859  56043000200  Wyoming  Washakie      0     3326     1317   \n",
       "72860  56043000301  Wyoming  Washakie      1     2665     1154   \n",
       "72861  56043000302  Wyoming  Washakie      1     2542     1021   \n",
       "72862  56045951100  Wyoming    Weston      0     3314     1322   \n",
       "72863  56045951300  Wyoming    Weston      1     3894     1699   \n",
       "\n",
       "       GroupQuartersFlag  NUMGQTRS  PCTGQTRS  LILATracts_1And10  ...  \\\n",
       "0                      0         0  0.000000                  0  ...   \n",
       "1                      0       181  0.083410                  0  ...   \n",
       "2                      0         0  0.000000                  0  ...   \n",
       "3                      0         0  0.000000                  0  ...   \n",
       "4                      0       181  0.016812                  0  ...   \n",
       "...                  ...       ...       ...                ...  ...   \n",
       "72859                  0        57  0.017138                  0  ...   \n",
       "72860                  0        10  0.003752                  0  ...   \n",
       "72861                  0        73  0.028717                  0  ...   \n",
       "72862                  0       252  0.076041                  0  ...   \n",
       "72863                  0        61  0.015665                  0  ...   \n",
       "\n",
       "       TractWhite  TractBlack  TractAsian  TractNHOPI  TractAIAN  \\\n",
       "0            1622         217          14           0         14   \n",
       "1             888        1217           5           0          5   \n",
       "2            2576         647          17           5         11   \n",
       "3            4086         193          18           4         11   \n",
       "4            8666        1437         296           9         48   \n",
       "...           ...         ...         ...         ...        ...   \n",
       "72859        3106           6          15           0         27   \n",
       "72860        2377           5          23           0         40   \n",
       "72861        2312          11          10           1         26   \n",
       "72862        3179          15          10           1         47   \n",
       "72863        3706           6          10           2         44   \n",
       "\n",
       "       TractOMultir  TractHispanic  TractHUNV  TractSNAP  Income  \n",
       "0                45             44         26        112       1  \n",
       "1                55             75         87        202       1  \n",
       "2               117             87        108        120       1  \n",
       "3                74             85         19         82       1  \n",
       "4               310            355        198        488       1  \n",
       "...             ...            ...        ...        ...     ...  \n",
       "72859           172            309         56        116       1  \n",
       "72860           220            446        114        124       1  \n",
       "72861           182            407         82         97       1  \n",
       "72862            62             91        108         50       1  \n",
       "72863           126            125         95        168       1  \n",
       "\n",
       "[72864 rows x 148 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Poverty Guidelines U.S. 2015 family of 4 is $24,250\n",
    "conditions = [(food_atlasMFI_df['MedianFamilyIncome'] <= 24250), \n",
    "              (food_atlasMFI_df['MedianFamilyIncome'] > 24250)]\n",
    "values = [0, 1]\n",
    "food_atlasMFI_df[\"Income\"] = np.select(conditions, values)\n",
    "food_atlasMFI_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CensusTract       int64\n",
       "State            object\n",
       "County           object\n",
       "Urban             int64\n",
       "POP2010           int64\n",
       "                  ...  \n",
       "TractOMultir      int64\n",
       "TractHispanic     int64\n",
       "TractHUNV         int64\n",
       "TractSNAP         int64\n",
       "Income            int32\n",
       "Length: 148, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "food_atlasMFI_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export to csv \n",
    "# food_atlasMFI_df.to_csv(\"food_atlasMFI.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Income</th>\n",
       "      <th>lasnaphalfshare</th>\n",
       "      <th>lahunvhalfshare</th>\n",
       "      <th>lasnap1share</th>\n",
       "      <th>lahunv1share</th>\n",
       "      <th>lasnap10share</th>\n",
       "      <th>lahunv10share</th>\n",
       "      <th>lasnap20share</th>\n",
       "      <th>lahunv20share</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.147009</td>\n",
       "      <td>0.031106</td>\n",
       "      <td>0.114786</td>\n",
       "      <td>0.014102</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.171424</td>\n",
       "      <td>0.078908</td>\n",
       "      <td>0.056125</td>\n",
       "      <td>0.029123</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.079760</td>\n",
       "      <td>0.039124</td>\n",
       "      <td>0.040019</td>\n",
       "      <td>0.010594</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.039322</td>\n",
       "      <td>0.010177</td>\n",
       "      <td>0.014171</td>\n",
       "      <td>0.005100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.083065</td>\n",
       "      <td>0.031748</td>\n",
       "      <td>0.029384</td>\n",
       "      <td>0.010940</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72859</th>\n",
       "      <td>1</td>\n",
       "      <td>0.089568</td>\n",
       "      <td>0.043199</td>\n",
       "      <td>0.070881</td>\n",
       "      <td>0.027829</td>\n",
       "      <td>0.027191</td>\n",
       "      <td>0.009948</td>\n",
       "      <td>0.022738</td>\n",
       "      <td>0.009584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72860</th>\n",
       "      <td>1</td>\n",
       "      <td>0.029293</td>\n",
       "      <td>0.037033</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72861</th>\n",
       "      <td>1</td>\n",
       "      <td>0.034696</td>\n",
       "      <td>0.027687</td>\n",
       "      <td>0.006754</td>\n",
       "      <td>0.005270</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72862</th>\n",
       "      <td>1</td>\n",
       "      <td>0.029139</td>\n",
       "      <td>0.067493</td>\n",
       "      <td>0.024003</td>\n",
       "      <td>0.060575</td>\n",
       "      <td>0.010547</td>\n",
       "      <td>0.028515</td>\n",
       "      <td>0.002164</td>\n",
       "      <td>0.005948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72863</th>\n",
       "      <td>1</td>\n",
       "      <td>0.065055</td>\n",
       "      <td>0.049088</td>\n",
       "      <td>0.034283</td>\n",
       "      <td>0.019168</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72864 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Income  lasnaphalfshare  lahunvhalfshare  lasnap1share  lahunv1share  \\\n",
       "0           1         0.147009         0.031106      0.114786      0.014102   \n",
       "1           1         0.171424         0.078908      0.056125      0.029123   \n",
       "2           1         0.079760         0.039124      0.040019      0.010594   \n",
       "3           1         0.039322         0.010177      0.014171      0.005100   \n",
       "4           1         0.083065         0.031748      0.029384      0.010940   \n",
       "...       ...              ...              ...           ...           ...   \n",
       "72859       1         0.089568         0.043199      0.070881      0.027829   \n",
       "72860       1         0.029293         0.037033      0.000000      0.000000   \n",
       "72861       1         0.034696         0.027687      0.006754      0.005270   \n",
       "72862       1         0.029139         0.067493      0.024003      0.060575   \n",
       "72863       1         0.065055         0.049088      0.034283      0.019168   \n",
       "\n",
       "       lasnap10share  lahunv10share  lasnap20share  lahunv20share  \n",
       "0           0.000000       0.000000       0.000000       0.000000  \n",
       "1           0.000000       0.000000       0.000000       0.000000  \n",
       "2           0.000000       0.000000       0.000000       0.000000  \n",
       "3           0.000000       0.000000       0.000000       0.000000  \n",
       "4           0.000000       0.000000       0.000000       0.000000  \n",
       "...              ...            ...            ...            ...  \n",
       "72859       0.027191       0.009948       0.022738       0.009584  \n",
       "72860       0.000000       0.000000       0.000000       0.000000  \n",
       "72861       0.000000       0.000000       0.000000       0.000000  \n",
       "72862       0.010547       0.028515       0.002164       0.005948  \n",
       "72863       0.000000       0.000000       0.000000       0.000000  \n",
       "\n",
       "[72864 rows x 9 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create new df with select feature columns for all of U.S. (not only for Texas), with 72,864 rows\n",
    "# Use this df as ML Training set, this input data has no categorical data types, it can be provided to the neural network model in its raw form \n",
    "food_desertUS_df = food_atlasMFI_df[[\"Income\", \"lasnaphalfshare\", \"lahunvhalfshare\", \"lasnap1share\", \"lahunv1share\", \"lasnap10share\", \"lahunv10share\", \"lasnap20share\", \"lahunv20share\"]]\n",
    "food_desertUS_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export to csv\n",
    "# food_desertUS_df.to_csv(\"food_desertUS.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1\n",
       "0  0.0  1.0\n",
       "1  0.0  1.0\n",
       "2  0.0  1.0\n",
       "3  0.0  1.0\n",
       "4  0.0  1.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a OneHotEncoder instance for column Income, and although the Income data value are numerical, not categorical, \n",
    "#  to ensure that the values are encoded for the ML model.\n",
    "enc = OneHotEncoder(sparse=False)\n",
    "\n",
    "# Fit and transform the OneHotEncoder using the categorical variable list\n",
    "encode_df = pd.DataFrame(enc.fit_transform(food_desertUS_df.Income.values.reshape(-1,1)))\n",
    "encode_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    float64\n",
       "1    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export to csv\n",
    "# encode_df.to_csv(\"encode.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Models\n",
    "### ML Training on full U.S. Census dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the preprocessed dataframe into our features and target arrays\n",
    "#  Remove Income target from features data. Establish the target output, y, as the encoded Income column for \"1\".\n",
    "#   The two columns of the endoce_df are redundant to each other, as they are dichotomous, we only need one of the colunns.\n",
    "#y = encode_df[1]\n",
    "y = food_desertUS_df['Income']\n",
    "X = food_desertUS_df.drop(columns=\"Income\").values\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create StandardScaler instance. Using the StandardScaler module to standardize our numerical variables, we reduce the overall\n",
    "#  likelihood that outliers, variables of different units, or skewed distributions will have a negative impact on the model's performance.\n",
    "scaler = StandardScaler()\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 30)                270       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 9)                 279       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 10        \n",
      "=================================================================\n",
      "Total params: 559\n",
      "Trainable params: 559\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net. the number of input features and the hidden nodes for each layer.\n",
    "# A rule of thumb for a basic neural network is to have two to three times the amount of neurons in \n",
    "# the hidden layer as the number of inputs.\n",
    "number_input_features = len(X_train[0])\n",
    "hidden_nodes_layer1 = 30\n",
    "hidden_nodes_layer2 = 9\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\"))\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the checkpoint path and filenames\n",
    "os.makedirs(\"checkpoints/\",exist_ok=True)\n",
    "checkpoint_path = \"checkpoints/weights.{epoch:02d}.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " 979/1708 [================>.............] - ETA: 0s - loss: 0.3401 - accuracy: 0.8575\n",
      "Epoch 00001: saving model to checkpoints\\weights.01.hdf5\n",
      "1708/1708 [==============================] - 2s 676us/step - loss: 0.2784 - accuracy: 0.8947\n",
      "Epoch 2/100\n",
      " 276/1708 [===>..........................] - ETA: 0s - loss: 0.1278 - accuracy: 0.9635\n",
      "Epoch 00002: saving model to checkpoints\\weights.02.hdf5\n",
      "1286/1708 [=====================>........] - ETA: 0s - loss: 0.1298 - accuracy: 0.9625\n",
      "Epoch 00002: saving model to checkpoints\\weights.02.hdf5\n",
      "1708/1708 [==============================] - 1s 627us/step - loss: 0.1301 - accuracy: 0.9622\n",
      "Epoch 3/100\n",
      " 541/1708 [========>.....................] - ETA: 0s - loss: 0.1322 - accuracy: 0.9595\n",
      "Epoch 00003: saving model to checkpoints\\weights.03.hdf5\n",
      "1505/1708 [=========================>....] - ETA: 0s - loss: 0.1291 - accuracy: 0.9608\n",
      "Epoch 00003: saving model to checkpoints\\weights.03.hdf5\n",
      "1708/1708 [==============================] - 1s 620us/step - loss: 0.1288 - accuracy: 0.9609\n",
      "Epoch 4/100\n",
      " 876/1708 [==============>...............] - ETA: 0s - loss: 0.1249 - accuracy: 0.9615\n",
      "Epoch 00004: saving model to checkpoints\\weights.04.hdf5\n",
      "1708/1708 [==============================] - 1s 616us/step - loss: 0.1249 - accuracy: 0.9617\n",
      "Epoch 5/100\n",
      " 159/1708 [=>............................] - ETA: 0s - loss: 0.1057 - accuracy: 0.9692\n",
      "Epoch 00005: saving model to checkpoints\\weights.05.hdf5\n",
      "1115/1708 [==================>...........] - ETA: 0s - loss: 0.1197 - accuracy: 0.9632\n",
      "Epoch 00005: saving model to checkpoints\\weights.05.hdf5\n",
      "1708/1708 [==============================] - 1s 639us/step - loss: 0.1210 - accuracy: 0.9626\n",
      "Epoch 6/100\n",
      " 387/1708 [=====>........................] - ETA: 0s - loss: 0.1254 - accuracy: 0.9629\n",
      "Epoch 00006: saving model to checkpoints\\weights.06.hdf5\n",
      "1437/1708 [========================>.....] - ETA: 0s - loss: 0.1236 - accuracy: 0.9620\n",
      "Epoch 00006: saving model to checkpoints\\weights.06.hdf5\n",
      "1708/1708 [==============================] - 1s 668us/step - loss: 0.1231 - accuracy: 0.9621\n",
      "Epoch 7/100\n",
      " 749/1708 [============>.................] - ETA: 0s - loss: 0.1214 - accuracy: 0.9628\n",
      "Epoch 00007: saving model to checkpoints\\weights.07.hdf5\n",
      "1708/1708 [==============================] - 1s 619us/step - loss: 0.1211 - accuracy: 0.9624\n",
      "Epoch 8/100\n",
      "   1/1708 [..............................] - ETA: 1s - loss: 0.2470 - accuracy: 0.9062\n",
      "Epoch 00008: saving model to checkpoints\\weights.08.hdf5\n",
      " 967/1708 [===============>..............] - ETA: 0s - loss: 0.1178 - accuracy: 0.9629\n",
      "Epoch 00008: saving model to checkpoints\\weights.08.hdf5\n",
      "1708/1708 [==============================] - 1s 654us/step - loss: 0.1183 - accuracy: 0.9625\n",
      "Epoch 9/100\n",
      " 281/1708 [===>..........................] - ETA: 1s - loss: 0.1136 - accuracy: 0.9625\n",
      "Epoch 00009: saving model to checkpoints\\weights.09.hdf5\n",
      "1300/1708 [=====================>........] - ETA: 0s - loss: 0.1173 - accuracy: 0.9622\n",
      "Epoch 00009: saving model to checkpoints\\weights.09.hdf5\n",
      "1708/1708 [==============================] - 1s 661us/step - loss: 0.1176 - accuracy: 0.9621\n",
      "Epoch 10/100\n",
      " 624/1708 [=========>....................] - ETA: 0s - loss: 0.1185 - accuracy: 0.9623\n",
      "Epoch 00010: saving model to checkpoints\\weights.10.hdf5\n",
      "1557/1708 [==========================>...] - ETA: 0s - loss: 0.1176 - accuracy: 0.9624\n",
      "Epoch 00010: saving model to checkpoints\\weights.10.hdf5\n",
      "1708/1708 [==============================] - 1s 677us/step - loss: 0.1176 - accuracy: 0.9624\n",
      "Epoch 11/100\n",
      " 872/1708 [==============>...............] - ETA: 0s - loss: 0.1155 - accuracy: 0.9628 ETA: 1s - loss: 0.1128 \n",
      "Epoch 00011: saving model to checkpoints\\weights.11.hdf5\n",
      "1708/1708 [==============================] - 1s 620us/step - loss: 0.1162 - accuracy: 0.9626\n",
      "Epoch 12/100\n",
      " 155/1708 [=>............................] - ETA: 1s - loss: 0.1297 - accuracy: 0.9587\n",
      "Epoch 00012: saving model to checkpoints\\weights.12.hdf5\n",
      "1195/1708 [===================>..........] - ETA: 0s - loss: 0.1179 - accuracy: 0.9620\n",
      "Epoch 00012: saving model to checkpoints\\weights.12.hdf5\n",
      "1708/1708 [==============================] - 1s 633us/step - loss: 0.1174 - accuracy: 0.9621\n",
      "Epoch 13/100\n",
      " 501/1708 [=======>......................] - ETA: 0s - loss: 0.1162 - accuracy: 0.9636\n",
      "Epoch 00013: saving model to checkpoints\\weights.13.hdf5\n",
      "1429/1708 [========================>.....] - ETA: 0s - loss: 0.1172 - accuracy: 0.9629\n",
      "Epoch 00013: saving model to checkpoints\\weights.13.hdf5\n",
      "1708/1708 [==============================] - 1s 653us/step - loss: 0.1171 - accuracy: 0.9629\n",
      "Epoch 14/100\n",
      " 795/1708 [============>.................] - ETA: 0s - loss: 0.1165 - accuracy: 0.9628\n",
      "Epoch 00014: saving model to checkpoints\\weights.14.hdf5\n",
      "1708/1708 [==============================] - 1s 700us/step - loss: 0.1165 - accuracy: 0.9625\n",
      "Epoch 15/100\n",
      "  70/1708 [>.............................] - ETA: 1s - loss: 0.1281 - accuracy: 0.9581\n",
      "Epoch 00015: saving model to checkpoints\\weights.15.hdf5\n",
      "1023/1708 [================>.............] - ETA: 0s - loss: 0.1160 - accuracy: 0.9625\n",
      "Epoch 00015: saving model to checkpoints\\weights.15.hdf5\n",
      "1708/1708 [==============================] - 1s 711us/step - loss: 0.1163 - accuracy: 0.9622\n",
      "Epoch 16/100\n",
      " 312/1708 [====>.........................] - ETA: 0s - loss: 0.1224 - accuracy: 0.9606\n",
      "Epoch 00016: saving model to checkpoints\\weights.16.hdf5\n",
      "1375/1708 [=======================>......] - ETA: 0s - loss: 0.1181 - accuracy: 0.9614\n",
      "Epoch 00016: saving model to checkpoints\\weights.16.hdf5\n",
      "1708/1708 [==============================] - 1s 709us/step - loss: 0.1177 - accuracy: 0.9614\n",
      "Epoch 17/100\n",
      " 598/1708 [=========>....................] - ETA: 0s - loss: 0.1156 - accuracy: 0.9633\n",
      "Epoch 00017: saving model to checkpoints\\weights.17.hdf5\n",
      "1666/1708 [============================>.] - ETA: 0s - loss: 0.1156 - accuracy: 0.9627\n",
      "Epoch 00017: saving model to checkpoints\\weights.17.hdf5\n",
      "1708/1708 [==============================] - 1s 646us/step - loss: 0.1156 - accuracy: 0.9626\n",
      "Epoch 18/100\n",
      " 921/1708 [===============>..............] - ETA: 0s - loss: 0.1163 - accuracy: 0.9624\n",
      "Epoch 00018: saving model to checkpoints\\weights.18.hdf5\n",
      "1708/1708 [==============================] - 1s 634us/step - loss: 0.1162 - accuracy: 0.9623\n",
      "Epoch 19/100\n",
      " 229/1708 [===>..........................] - ETA: 0s - loss: 0.1205 - accuracy: 0.9625\n",
      "Epoch 00019: saving model to checkpoints\\weights.19.hdf5\n",
      "1203/1708 [====================>.........] - ETA: 0s - loss: 0.1193 - accuracy: 0.9619\n",
      "Epoch 00019: saving model to checkpoints\\weights.19.hdf5\n",
      "1708/1708 [==============================] - 1s 657us/step - loss: 0.1183 - accuracy: 0.9621\n",
      "Epoch 20/100\n",
      " 508/1708 [=======>......................] - ETA: 0s - loss: 0.1220 - accuracy: 0.9596\n",
      "Epoch 00020: saving model to checkpoints\\weights.20.hdf5\n",
      "1474/1708 [========================>.....] - ETA: 0s - loss: 0.1182 - accuracy: 0.9609\n",
      "Epoch 00020: saving model to checkpoints\\weights.20.hdf5\n",
      "1708/1708 [==============================] - 1s 689us/step - loss: 0.1179 - accuracy: 0.9610\n",
      "Epoch 21/100\n",
      " 777/1708 [============>.................] - ETA: 0s - loss: 0.1239 - accuracy: 0.9596\n",
      "Epoch 00021: saving model to checkpoints\\weights.21.hdf5\n",
      "1708/1708 [==============================] - 1s 668us/step - loss: 0.1198 - accuracy: 0.9609\n",
      "Epoch 22/100\n",
      "  71/1708 [>.............................] - ETA: 1s - loss: 0.1334 - accuracy: 0.9569\n",
      "Epoch 00022: saving model to checkpoints\\weights.22.hdf5\n",
      "1094/1708 [==================>...........] - ETA: 0s - loss: 0.1147 - accuracy: 0.9627\n",
      "Epoch 00022: saving model to checkpoints\\weights.22.hdf5\n",
      "1708/1708 [==============================] - 1s 641us/step - loss: 0.1150 - accuracy: 0.9624\n",
      "Epoch 23/100\n",
      " 424/1708 [======>.......................] - ETA: 0s - loss: 0.1181 - accuracy: 0.9615\n",
      "Epoch 00023: saving model to checkpoints\\weights.23.hdf5\n",
      "1400/1708 [=======================>......] - ETA: 0s - loss: 0.1164 - accuracy: 0.9617\n",
      "Epoch 00023: saving model to checkpoints\\weights.23.hdf5\n",
      "1708/1708 [==============================] - 1s 658us/step - loss: 0.1164 - accuracy: 0.9618\n",
      "Epoch 24/100\n",
      " 662/1708 [==========>...................] - ETA: 0s - loss: 0.1079 - accuracy: 0.9645\n",
      "Epoch 00024: saving model to checkpoints\\weights.24.hdf5\n",
      "1708/1708 [==============================] - 1s 677us/step - loss: 0.1120 - accuracy: 0.9632\n",
      "Epoch 25/100\n",
      "   1/1708 [..............................] - ETA: 1s - loss: 0.1094 - accuracy: 0.9688\n",
      "Epoch 00025: saving model to checkpoints\\weights.25.hdf5\n",
      " 999/1708 [================>.............] - ETA: 0s - loss: 0.1111 - accuracy: 0.9634\n",
      "Epoch 00025: saving model to checkpoints\\weights.25.hdf5\n",
      "1708/1708 [==============================] - 1s 737us/step - loss: 0.1127 - accuracy: 0.9630\n",
      "Epoch 26/100\n",
      " 234/1708 [===>..........................] - ETA: 0s - loss: 0.1130 - accuracy: 0.9653\n",
      "Epoch 00026: saving model to checkpoints\\weights.26.hdf5\n",
      "1269/1708 [=====================>........] - ETA: 0s - loss: 0.1146 - accuracy: 0.9631\n",
      "Epoch 00026: saving model to checkpoints\\weights.26.hdf5\n",
      "1708/1708 [==============================] - 1s 646us/step - loss: 0.1148 - accuracy: 0.9629\n",
      "Epoch 27/100\n",
      " 577/1708 [=========>....................] - ETA: 0s - loss: 0.1090 - accuracy: 0.9639\n",
      "Epoch 00027: saving model to checkpoints\\weights.27.hdf5\n",
      "1563/1708 [==========================>...] - ETA: 0s - loss: 0.1119 - accuracy: 0.9631\n",
      "Epoch 00027: saving model to checkpoints\\weights.27.hdf5\n",
      "1708/1708 [==============================] - 1s 680us/step - loss: 0.1121 - accuracy: 0.9630\n",
      "Epoch 28/100\n",
      " 866/1708 [==============>...............] - ETA: 0s - loss: 0.1141 - accuracy: 0.9625\n",
      "Epoch 00028: saving model to checkpoints\\weights.28.hdf5\n",
      "1708/1708 [==============================] - 1s 665us/step - loss: 0.1148 - accuracy: 0.9623\n",
      "Epoch 29/100\n",
      " 124/1708 [=>............................] - ETA: 1s - loss: 0.1275 - accuracy: 0.9557\n",
      "Epoch 00029: saving model to checkpoints\\weights.29.hdf5\n",
      "1162/1708 [===================>..........] - ETA: 0s - loss: 0.1147 - accuracy: 0.9623\n",
      "Epoch 00029: saving model to checkpoints\\weights.29.hdf5\n",
      "1708/1708 [==============================] - 1s 779us/step - loss: 0.1145 - accuracy: 0.9624\n",
      "Epoch 30/100\n",
      " 406/1708 [======>.......................] - ETA: 0s - loss: 0.1136 - accuracy: 0.9620\n",
      "Epoch 00030: saving model to checkpoints\\weights.30.hdf5\n",
      "1421/1708 [=======================>......] - ETA: 0s - loss: 0.1147 - accuracy: 0.9618\n",
      "Epoch 00030: saving model to checkpoints\\weights.30.hdf5\n",
      "1708/1708 [==============================] - 1s 624us/step - loss: 0.1147 - accuracy: 0.9619\n",
      "Epoch 31/100\n",
      " 710/1708 [===========>..................] - ETA: 0s - loss: 0.1111 - accuracy: 0.9643\n",
      "Epoch 00031: saving model to checkpoints\\weights.31.hdf5\n",
      "1708/1708 [==============================] - 1s 657us/step - loss: 0.1127 - accuracy: 0.9633\n",
      "Epoch 32/100\n",
      "   1/1708 [..............................] - ETA: 1s - loss: 0.0854 - accuracy: 0.9688\n",
      "Epoch 00032: saving model to checkpoints\\weights.32.hdf5\n",
      "1018/1708 [================>.............] - ETA: 0s - loss: 0.1117 - accuracy: 0.9629\n",
      "Epoch 00032: saving model to checkpoints\\weights.32.hdf5\n",
      "1708/1708 [==============================] - 1s 686us/step - loss: 0.1135 - accuracy: 0.9625\n",
      "Epoch 33/100\n",
      " 339/1708 [====>.........................] - ETA: 1s - loss: 0.1194 - accuracy: 0.9606\n",
      "Epoch 00033: saving model to checkpoints\\weights.33.hdf5\n",
      "1270/1708 [=====================>........] - ETA: 0s - loss: 0.1174 - accuracy: 0.9618\n",
      "Epoch 00033: saving model to checkpoints\\weights.33.hdf5\n",
      "1708/1708 [==============================] - 1s 709us/step - loss: 0.1171 - accuracy: 0.9618\n",
      "Epoch 34/100\n",
      " 602/1708 [=========>....................] - ETA: 0s - loss: 0.1138 - accuracy: 0.9633\n",
      "Epoch 00034: saving model to checkpoints\\weights.34.hdf5\n",
      "1562/1708 [==========================>...] - ETA: 0s - loss: 0.1146 - accuracy: 0.9625\n",
      "Epoch 00034: saving model to checkpoints\\weights.34.hdf5\n",
      "1708/1708 [==============================] - 1s 682us/step - loss: 0.1145 - accuracy: 0.9625\n",
      "Epoch 35/100\n",
      " 924/1708 [===============>..............] - ETA: 0s - loss: 0.1163 - accuracy: 0.9614\n",
      "Epoch 00035: saving model to checkpoints\\weights.35.hdf5\n",
      "1708/1708 [==============================] - 1s 667us/step - loss: 0.1164 - accuracy: 0.9616\n",
      "Epoch 36/100\n",
      " 218/1708 [==>...........................] - ETA: 1s - loss: 0.1258 - accuracy: 0.9593\n",
      "Epoch 00036: saving model to checkpoints\\weights.36.hdf5\n",
      "1196/1708 [====================>.........] - ETA: 0s - loss: 0.1160 - accuracy: 0.9624\n",
      "Epoch 00036: saving model to checkpoints\\weights.36.hdf5\n",
      "1708/1708 [==============================] - 1s 721us/step - loss: 0.1158 - accuracy: 0.9623\n",
      "Epoch 37/100\n",
      " 490/1708 [=======>......................] - ETA: 0s - loss: 0.1216 - accuracy: 0.9598\n",
      "Epoch 00037: saving model to checkpoints\\weights.37.hdf5\n",
      "1505/1708 [=========================>....] - ETA: 0s - loss: 0.1162 - accuracy: 0.9616\n",
      "Epoch 00037: saving model to checkpoints\\weights.37.hdf5\n",
      "1708/1708 [==============================] - 1s 741us/step - loss: 0.1160 - accuracy: 0.9617\n",
      "Epoch 38/100\n",
      " 787/1708 [============>.................] - ETA: 0s - loss: 0.1164 - accuracy: 0.9630\n",
      "Epoch 00038: saving model to checkpoints\\weights.38.hdf5\n",
      "1708/1708 [==============================] - 1s 705us/step - loss: 0.1159 - accuracy: 0.9625\n",
      "Epoch 39/100\n",
      "  76/1708 [>.............................] - ETA: 1s - loss: 0.1305 - accuracy: 0.9548\n",
      "Epoch 00039: saving model to checkpoints\\weights.39.hdf5\n",
      "1062/1708 [=================>............] - ETA: 0s - loss: 0.1203 - accuracy: 0.9604\n",
      "Epoch 00039: saving model to checkpoints\\weights.39.hdf5\n",
      "1708/1708 [==============================] - 1s 733us/step - loss: 0.1184 - accuracy: 0.9611\n",
      "Epoch 40/100\n",
      " 357/1708 [=====>........................] - ETA: 0s - loss: 0.1160 - accuracy: 0.9603\n",
      "Epoch 00040: saving model to checkpoints\\weights.40.hdf5\n",
      "1343/1708 [======================>.......] - ETA: 0s - loss: 0.1144 - accuracy: 0.9617\n",
      "Epoch 00040: saving model to checkpoints\\weights.40.hdf5\n",
      "1708/1708 [==============================] - 1s 713us/step - loss: 0.1143 - accuracy: 0.9618\n",
      "Epoch 41/100\n",
      " 651/1708 [==========>...................] - ETA: 0s - loss: 0.1118 - accuracy: 0.9633\n",
      "Epoch 00041: saving model to checkpoints\\weights.41.hdf5\n",
      "1662/1708 [============================>.] - ETA: 0s - loss: 0.1132 - accuracy: 0.9626\n",
      "Epoch 00041: saving model to checkpoints\\weights.41.hdf5\n",
      "1708/1708 [==============================] - 1s 739us/step - loss: 0.1132 - accuracy: 0.9626\n",
      "Epoch 42/100\n",
      " 918/1708 [===============>..............] - ETA: 0s - loss: 0.1149 - accuracy: 0.9628\n",
      "Epoch 00042: saving model to checkpoints\\weights.42.hdf5\n",
      "1708/1708 [==============================] - 1s 722us/step - loss: 0.1146 - accuracy: 0.9626\n",
      "Epoch 43/100\n",
      " 221/1708 [==>...........................] - ETA: 1s - loss: 0.1328 - accuracy: 0.9565\n",
      "Epoch 00043: saving model to checkpoints\\weights.43.hdf5\n",
      "1212/1708 [====================>.........] - ETA: 0s - loss: 0.1199 - accuracy: 0.9602\n",
      "Epoch 00043: saving model to checkpoints\\weights.43.hdf5\n",
      "1708/1708 [==============================] - 1s 715us/step - loss: 0.1184 - accuracy: 0.9608\n",
      "Epoch 44/100\n",
      " 497/1708 [=======>......................] - ETA: 0s - loss: 0.1202 - accuracy: 0.9588\n",
      "Epoch 00044: saving model to checkpoints\\weights.44.hdf5\n",
      "1496/1708 [=========================>....] - ETA: 0s - loss: 0.1162 - accuracy: 0.9607\n",
      "Epoch 00044: saving model to checkpoints\\weights.44.hdf5\n",
      "1708/1708 [==============================] - 1s 720us/step - loss: 0.1159 - accuracy: 0.9609\n",
      "Epoch 45/100\n",
      " 812/1708 [=============>................] - ETA: 0s - loss: 0.1062 - accuracy: 0.9660\n",
      "Epoch 00045: saving model to checkpoints\\weights.45.hdf5\n",
      "1708/1708 [==============================] - 1s 684us/step - loss: 0.1100 - accuracy: 0.9643\n",
      "Epoch 46/100\n",
      "  67/1708 [>.............................] - ETA: 1s - loss: 0.1162 - accuracy: 0.9584\n",
      "Epoch 00046: saving model to checkpoints\\weights.46.hdf5\n",
      "1130/1708 [==================>...........] - ETA: 0s - loss: 0.1151 - accuracy: 0.9617\n",
      "Epoch 00046: saving model to checkpoints\\weights.46.hdf5\n",
      "1708/1708 [==============================] - 1s 732us/step - loss: 0.1149 - accuracy: 0.9619\n",
      "Epoch 47/100\n",
      " 422/1708 [======>.......................] - ETA: 0s - loss: 0.1167 - accuracy: 0.9606\n",
      "Epoch 00047: saving model to checkpoints\\weights.47.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1421/1708 [=======================>......] - ETA: 0s - loss: 0.1151 - accuracy: 0.9616\n",
      "Epoch 00047: saving model to checkpoints\\weights.47.hdf5\n",
      "1708/1708 [==============================] - 1s 754us/step - loss: 0.1151 - accuracy: 0.9616\n",
      "Epoch 48/100\n",
      " 687/1708 [===========>..................] - ETA: 0s - loss: 0.1140 - accuracy: 0.9623\n",
      "Epoch 00048: saving model to checkpoints\\weights.48.hdf5\n",
      "1708/1708 [==============================] - 1s 652us/step - loss: 0.1136 - accuracy: 0.9625\n",
      "Epoch 49/100\n",
      "   1/1708 [..............................] - ETA: 1s - loss: 0.2330 - accuracy: 0.9375\n",
      "Epoch 00049: saving model to checkpoints\\weights.49.hdf5\n",
      " 969/1708 [================>.............] - ETA: 0s - loss: 0.1129 - accuracy: 0.9627\n",
      "Epoch 00049: saving model to checkpoints\\weights.49.hdf5\n",
      "1708/1708 [==============================] - 1s 730us/step - loss: 0.1136 - accuracy: 0.9626\n",
      "Epoch 50/100\n",
      " 279/1708 [===>..........................] - ETA: 1s - loss: 0.1091 - accuracy: 0.9641\n",
      "Epoch 00050: saving model to checkpoints\\weights.50.hdf5\n",
      "1258/1708 [=====================>........] - ETA: 0s - loss: 0.1126 - accuracy: 0.9632\n",
      "Epoch 00050: saving model to checkpoints\\weights.50.hdf5\n",
      "1708/1708 [==============================] - 1s 737us/step - loss: 0.1131 - accuracy: 0.9630\n",
      "Epoch 51/100\n",
      " 551/1708 [========>.....................] - ETA: 0s - loss: 0.1092 - accuracy: 0.9640\n",
      "Epoch 00051: saving model to checkpoints\\weights.51.hdf5\n",
      "1586/1708 [==========================>...] - ETA: 0s - loss: 0.1117 - accuracy: 0.9632\n",
      "Epoch 00051: saving model to checkpoints\\weights.51.hdf5\n",
      "1708/1708 [==============================] - 1s 765us/step - loss: 0.1118 - accuracy: 0.9631\n",
      "Epoch 52/100\n",
      " 819/1708 [=============>................] - ETA: 0s - loss: 0.1169 - accuracy: 0.9619\n",
      "Epoch 00052: saving model to checkpoints\\weights.52.hdf5\n",
      "1708/1708 [==============================] - 1s 690us/step - loss: 0.1165 - accuracy: 0.9618\n",
      "Epoch 53/100\n",
      " 150/1708 [=>............................] - ETA: 1s - loss: 0.1108 - accuracy: 0.9637\n",
      "Epoch 00053: saving model to checkpoints\\weights.53.hdf5\n",
      "1171/1708 [===================>..........] - ETA: 0s - loss: 0.1108 - accuracy: 0.9639\n",
      "Epoch 00053: saving model to checkpoints\\weights.53.hdf5\n",
      "1708/1708 [==============================] - 1s 685us/step - loss: 0.1116 - accuracy: 0.9635\n",
      "Epoch 54/100\n",
      " 412/1708 [======>.......................] - ETA: 0s - loss: 0.1098 - accuracy: 0.9633\n",
      "Epoch 00054: saving model to checkpoints\\weights.54.hdf5\n",
      "1442/1708 [========================>.....] - ETA: 0s - loss: 0.1111 - accuracy: 0.9630\n",
      "Epoch 00054: saving model to checkpoints\\weights.54.hdf5\n",
      "1708/1708 [==============================] - 1s 723us/step - loss: 0.1114 - accuracy: 0.9629\n",
      "Epoch 55/100\n",
      " 759/1708 [============>.................] - ETA: 0s - loss: 0.1134 - accuracy: 0.9625\n",
      "Epoch 00055: saving model to checkpoints\\weights.55.hdf5\n",
      "1708/1708 [==============================] - 1s 710us/step - loss: 0.1139 - accuracy: 0.9621\n",
      "Epoch 56/100\n",
      "   1/1708 [..............................] - ETA: 1s - loss: 0.1418 - accuracy: 0.9375\n",
      "Epoch 00056: saving model to checkpoints\\weights.56.hdf5\n",
      " 984/1708 [================>.............] - ETA: 0s - loss: 0.1105 - accuracy: 0.9635\n",
      "Epoch 00056: saving model to checkpoints\\weights.56.hdf5\n",
      "1708/1708 [==============================] - 1s 667us/step - loss: 0.1115 - accuracy: 0.9633\n",
      "Epoch 57/100\n",
      " 295/1708 [====>.........................] - ETA: 0s - loss: 0.0969 - accuracy: 0.9676\n",
      "Epoch 00057: saving model to checkpoints\\weights.57.hdf5\n",
      "1333/1708 [======================>.......] - ETA: 0s - loss: 0.1089 - accuracy: 0.9635\n",
      "Epoch 00057: saving model to checkpoints\\weights.57.hdf5\n",
      "1708/1708 [==============================] - 1s 700us/step - loss: 0.1099 - accuracy: 0.9632\n",
      "Epoch 58/100\n",
      " 640/1708 [==========>...................] - ETA: 0s - loss: 0.1096 - accuracy: 0.9632\n",
      "Epoch 00058: saving model to checkpoints\\weights.58.hdf5\n",
      "1598/1708 [===========================>..] - ETA: 0s - loss: 0.1106 - accuracy: 0.9630\n",
      "Epoch 00058: saving model to checkpoints\\weights.58.hdf5\n",
      "1708/1708 [==============================] - 1s 703us/step - loss: 0.1107 - accuracy: 0.9630\n",
      "Epoch 59/100\n",
      " 911/1708 [===============>..............] - ETA: 0s - loss: 0.1121 - accuracy: 0.9634\n",
      "Epoch 00059: saving model to checkpoints\\weights.59.hdf5\n",
      "1708/1708 [==============================] - 1s 676us/step - loss: 0.1123 - accuracy: 0.9631\n",
      "Epoch 60/100\n",
      " 209/1708 [==>...........................] - ETA: 1s - loss: 0.1215 - accuracy: 0.9597\n",
      "Epoch 00060: saving model to checkpoints\\weights.60.hdf5\n",
      "1174/1708 [===================>..........] - ETA: 0s - loss: 0.1164 - accuracy: 0.9612\n",
      "Epoch 00060: saving model to checkpoints\\weights.60.hdf5\n",
      "1708/1708 [==============================] - 1s 680us/step - loss: 0.1153 - accuracy: 0.9617\n",
      "Epoch 61/100\n",
      " 516/1708 [========>.....................] - ETA: 0s - loss: 0.1102 - accuracy: 0.9646\n",
      "Epoch 00061: saving model to checkpoints\\weights.61.hdf5\n",
      "1504/1708 [=========================>....] - ETA: 0s - loss: 0.1110 - accuracy: 0.9639\n",
      "Epoch 00061: saving model to checkpoints\\weights.61.hdf5\n",
      "1708/1708 [==============================] - 1s 682us/step - loss: 0.1113 - accuracy: 0.9638\n",
      "Epoch 62/100\n",
      " 749/1708 [============>.................] - ETA: 0s - loss: 0.1052 - accuracy: 0.9651\n",
      "Epoch 00062: saving model to checkpoints\\weights.62.hdf5\n",
      "1708/1708 [==============================] - 1s 676us/step - loss: 0.1090 - accuracy: 0.9637\n",
      "Epoch 63/100\n",
      "  67/1708 [>.............................] - ETA: 1s - loss: 0.1244 - accuracy: 0.9631\n",
      "Epoch 00063: saving model to checkpoints\\weights.63.hdf5\n",
      "1032/1708 [=================>............] - ETA: 0s - loss: 0.1115 - accuracy: 0.9636\n",
      "Epoch 00063: saving model to checkpoints\\weights.63.hdf5\n",
      "1708/1708 [==============================] - 1s 737us/step - loss: 0.1123 - accuracy: 0.9632\n",
      "Epoch 64/100\n",
      " 334/1708 [====>.........................] - ETA: 1s - loss: 0.1137 - accuracy: 0.9610\n",
      "Epoch 00064: saving model to checkpoints\\weights.64.hdf5\n",
      "1326/1708 [======================>.......] - ETA: 0s - loss: 0.1133 - accuracy: 0.9618\n",
      "Epoch 00064: saving model to checkpoints\\weights.64.hdf5\n",
      "1708/1708 [==============================] - 1s 733us/step - loss: 0.1134 - accuracy: 0.9620\n",
      "Epoch 65/100\n",
      " 634/1708 [==========>...................] - ETA: 0s - loss: 0.1062 - accuracy: 0.9657\n",
      "Epoch 00065: saving model to checkpoints\\weights.65.hdf5\n",
      "1656/1708 [============================>.] - ETA: 0s - loss: 0.1109 - accuracy: 0.9637\n",
      "Epoch 00065: saving model to checkpoints\\weights.65.hdf5\n",
      "1708/1708 [==============================] - 1s 706us/step - loss: 0.1109 - accuracy: 0.9637\n",
      "Epoch 66/100\n",
      " 960/1708 [===============>..............] - ETA: 0s - loss: 0.1179 - accuracy: 0.9597 ETA: 0s - loss: 0.1190 - accuracy\n",
      "Epoch 00066: saving model to checkpoints\\weights.66.hdf5\n",
      "1708/1708 [==============================] - 1s 706us/step - loss: 0.1164 - accuracy: 0.9607\n",
      "Epoch 67/100\n",
      " 221/1708 [==>...........................] - ETA: 1s - loss: 0.1123 - accuracy: 0.9634\n",
      "Epoch 00067: saving model to checkpoints\\weights.67.hdf5\n",
      "1246/1708 [====================>.........] - ETA: 0s - loss: 0.1161 - accuracy: 0.9613\n",
      "Epoch 00067: saving model to checkpoints\\weights.67.hdf5\n",
      "1708/1708 [==============================] - 1s 736us/step - loss: 0.1155 - accuracy: 0.9615\n",
      "Epoch 68/100\n",
      " 539/1708 [========>.....................] - ETA: 0s - loss: 0.1123 - accuracy: 0.9628\n",
      "Epoch 00068: saving model to checkpoints\\weights.68.hdf5\n",
      "1504/1708 [=========================>....] - ETA: 0s - loss: 0.1133 - accuracy: 0.9624\n",
      "Epoch 00068: saving model to checkpoints\\weights.68.hdf5\n",
      "1708/1708 [==============================] - 1s 722us/step - loss: 0.1133 - accuracy: 0.9624\n",
      "Epoch 69/100\n",
      " 828/1708 [=============>................] - ETA: 0s - loss: 0.1144 - accuracy: 0.9621\n",
      "Epoch 00069: saving model to checkpoints\\weights.69.hdf5\n",
      "1708/1708 [==============================] - 1s 684us/step - loss: 0.1137 - accuracy: 0.9623\n",
      "Epoch 70/100\n",
      "  80/1708 [>.............................] - ETA: 1s - loss: 0.1233 - accuracy: 0.9612\n",
      "Epoch 00070: saving model to checkpoints\\weights.70.hdf5\n",
      "1143/1708 [===================>..........] - ETA: 0s - loss: 0.1142 - accuracy: 0.9626\n",
      "Epoch 00070: saving model to checkpoints\\weights.70.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1708/1708 [==============================] - 1s 701us/step - loss: 0.1138 - accuracy: 0.9626\n",
      "Epoch 71/100\n",
      " 385/1708 [=====>........................] - ETA: 0s - loss: 0.1182 - accuracy: 0.9617\n",
      "Epoch 00071: saving model to checkpoints\\weights.71.hdf5\n",
      "1405/1708 [=======================>......] - ETA: 0s - loss: 0.1158 - accuracy: 0.9619\n",
      "Epoch 00071: saving model to checkpoints\\weights.71.hdf5\n",
      "1708/1708 [==============================] - 1s 715us/step - loss: 0.1153 - accuracy: 0.9620\n",
      "Epoch 72/100\n",
      " 677/1708 [==========>...................] - ETA: 0s - loss: 0.1121 - accuracy: 0.9625\n",
      "Epoch 00072: saving model to checkpoints\\weights.72.hdf5\n",
      "1708/1708 [==============================] - 1s 770us/step - loss: 0.1133 - accuracy: 0.9622\n",
      "Epoch 73/100\n",
      "   1/1708 [..............................] - ETA: 3s - loss: 0.1453 - accuracy: 0.9375\n",
      "Epoch 00073: saving model to checkpoints\\weights.73.hdf5\n",
      "1007/1708 [================>.............] - ETA: 0s - loss: 0.1133 - accuracy: 0.9618\n",
      "Epoch 00073: saving model to checkpoints\\weights.73.hdf5\n",
      "1708/1708 [==============================] - 1s 723us/step - loss: 0.1132 - accuracy: 0.9621\n",
      "Epoch 74/100\n",
      " 254/1708 [===>..........................] - ETA: 0s - loss: 0.1130 - accuracy: 0.9638\n",
      "Epoch 00074: saving model to checkpoints\\weights.74.hdf5\n",
      "1249/1708 [====================>.........] - ETA: 0s - loss: 0.1129 - accuracy: 0.9628\n",
      "Epoch 00074: saving model to checkpoints\\weights.74.hdf5\n",
      "1708/1708 [==============================] - 1s 672us/step - loss: 0.1131 - accuracy: 0.9626\n",
      "Epoch 75/100\n",
      " 606/1708 [=========>....................] - ETA: 0s - loss: 0.1125 - accuracy: 0.9639\n",
      "Epoch 00075: saving model to checkpoints\\weights.75.hdf5\n",
      "1580/1708 [==========================>...] - ETA: 0s - loss: 0.1135 - accuracy: 0.9630\n",
      "Epoch 00075: saving model to checkpoints\\weights.75.hdf5\n",
      "1708/1708 [==============================] - 1s 675us/step - loss: 0.1135 - accuracy: 0.9629\n",
      "Epoch 76/100\n",
      " 869/1708 [==============>...............] - ETA: 0s - loss: 0.1062 - accuracy: 0.9663\n",
      "Epoch 00076: saving model to checkpoints\\weights.76.hdf5\n",
      "1708/1708 [==============================] - 1s 701us/step - loss: 0.1094 - accuracy: 0.9648\n",
      "Epoch 77/100\n",
      " 158/1708 [=>............................] - ETA: 1s - loss: 0.1028 - accuracy: 0.9694\n",
      "Epoch 00077: saving model to checkpoints\\weights.77.hdf5\n",
      "1124/1708 [==================>...........] - ETA: 0s - loss: 0.1096 - accuracy: 0.9647\n",
      "Epoch 00077: saving model to checkpoints\\weights.77.hdf5\n",
      "1708/1708 [==============================] - 1s 702us/step - loss: 0.1107 - accuracy: 0.9639\n",
      "Epoch 78/100\n",
      " 415/1708 [======>.......................] - ETA: 0s - loss: 0.1171 - accuracy: 0.9601\n",
      "Epoch 00078: saving model to checkpoints\\weights.78.hdf5\n",
      "1476/1708 [========================>.....] - ETA: 0s - loss: 0.1151 - accuracy: 0.9616\n",
      "Epoch 00078: saving model to checkpoints\\weights.78.hdf5\n",
      "1708/1708 [==============================] - 1s 718us/step - loss: 0.1149 - accuracy: 0.9617\n",
      "Epoch 79/100\n",
      " 766/1708 [============>.................] - ETA: 0s - loss: 0.1187 - accuracy: 0.9613\n",
      "Epoch 00079: saving model to checkpoints\\weights.79.hdf5\n",
      "1708/1708 [==============================] - 1s 666us/step - loss: 0.1160 - accuracy: 0.9619\n",
      "Epoch 80/100\n",
      "  63/1708 [>.............................] - ETA: 1s - loss: 0.0925 - accuracy: 0.9719\n",
      "Epoch 00080: saving model to checkpoints\\weights.80.hdf5\n",
      "1045/1708 [=================>............] - ETA: 0s - loss: 0.1093 - accuracy: 0.9636\n",
      "Epoch 00080: saving model to checkpoints\\weights.80.hdf5\n",
      "1708/1708 [==============================] - 1s 708us/step - loss: 0.1106 - accuracy: 0.9632\n",
      "Epoch 81/100\n",
      " 351/1708 [=====>........................] - ETA: 0s - loss: 0.1208 - accuracy: 0.9609\n",
      "Epoch 00081: saving model to checkpoints\\weights.81.hdf5\n",
      "1300/1708 [=====================>........] - ETA: 0s - loss: 0.1168 - accuracy: 0.9619\n",
      "Epoch 00081: saving model to checkpoints\\weights.81.hdf5\n",
      "1708/1708 [==============================] - 1s 651us/step - loss: 0.1160 - accuracy: 0.9620\n",
      "Epoch 82/100\n",
      " 606/1708 [=========>....................] - ETA: 0s - loss: 0.1178 - accuracy: 0.9592\n",
      "Epoch 00082: saving model to checkpoints\\weights.82.hdf5\n",
      "1637/1708 [===========================>..] - ETA: 0s - loss: 0.1145 - accuracy: 0.9613\n",
      "Epoch 00082: saving model to checkpoints\\weights.82.hdf5\n",
      "1708/1708 [==============================] - 1s 713us/step - loss: 0.1145 - accuracy: 0.9613\n",
      "Epoch 83/100\n",
      " 921/1708 [===============>..............] - ETA: 0s - loss: 0.1086 - accuracy: 0.9638\n",
      "Epoch 00083: saving model to checkpoints\\weights.83.hdf5\n",
      "1708/1708 [==============================] - 1s 690us/step - loss: 0.1100 - accuracy: 0.9635\n",
      "Epoch 84/100\n",
      " 165/1708 [=>............................] - ETA: 0s - loss: 0.1163 - accuracy: 0.9606\n",
      "Epoch 00084: saving model to checkpoints\\weights.84.hdf5\n",
      "1197/1708 [====================>.........] - ETA: 0s - loss: 0.1129 - accuracy: 0.9624\n",
      "Epoch 00084: saving model to checkpoints\\weights.84.hdf5\n",
      "1708/1708 [==============================] - 1s 594us/step - loss: 0.1129 - accuracy: 0.9624\n",
      "Epoch 85/100\n",
      " 444/1708 [======>.......................] - ETA: 0s - loss: 0.1212 - accuracy: 0.9624\n",
      "Epoch 00085: saving model to checkpoints\\weights.85.hdf5\n",
      "1485/1708 [=========================>....] - ETA: 0s - loss: 0.1155 - accuracy: 0.9627\n",
      "Epoch 00085: saving model to checkpoints\\weights.85.hdf5\n",
      "1708/1708 [==============================] - 1s 664us/step - loss: 0.1152 - accuracy: 0.9627\n",
      "Epoch 86/100\n",
      " 817/1708 [=============>................] - ETA: 0s - loss: 0.1092 - accuracy: 0.9638\n",
      "Epoch 00086: saving model to checkpoints\\weights.86.hdf5\n",
      "1708/1708 [==============================] - 1s 626us/step - loss: 0.1110 - accuracy: 0.9632\n",
      "Epoch 87/100\n",
      "  76/1708 [>.............................] - ETA: 1s - loss: 0.0947 - accuracy: 0.9704\n",
      "Epoch 00087: saving model to checkpoints\\weights.87.hdf5\n",
      "1081/1708 [=================>............] - ETA: 0s - loss: 0.1068 - accuracy: 0.9654\n",
      "Epoch 00087: saving model to checkpoints\\weights.87.hdf5\n",
      "1708/1708 [==============================] - 1s 627us/step - loss: 0.1090 - accuracy: 0.9643\n",
      "Epoch 88/100\n",
      " 327/1708 [====>.........................] - ETA: 0s - loss: 0.1169 - accuracy: 0.9606\n",
      "Epoch 00088: saving model to checkpoints\\weights.88.hdf5\n",
      "1349/1708 [======================>.......] - ETA: 0s - loss: 0.1152 - accuracy: 0.9613\n",
      "Epoch 00088: saving model to checkpoints\\weights.88.hdf5\n",
      "1708/1708 [==============================] - 1s 613us/step - loss: 0.1148 - accuracy: 0.9615\n",
      "Epoch 89/100\n",
      " 653/1708 [==========>...................] - ETA: 0s - loss: 0.1181 - accuracy: 0.9605\n",
      "Epoch 00089: saving model to checkpoints\\weights.89.hdf5\n",
      "1681/1708 [============================>.] - ETA: 0s - loss: 0.1145 - accuracy: 0.9619\n",
      "Epoch 00089: saving model to checkpoints\\weights.89.hdf5\n",
      "1708/1708 [==============================] - 1s 608us/step - loss: 0.1145 - accuracy: 0.9619\n",
      "Epoch 90/100\n",
      " 898/1708 [==============>...............] - ETA: 0s - loss: 0.1178 - accuracy: 0.9614\n",
      "Epoch 00090: saving model to checkpoints\\weights.90.hdf5\n",
      "1708/1708 [==============================] - 1s 616us/step - loss: 0.1155 - accuracy: 0.9617\n",
      "Epoch 91/100\n",
      " 232/1708 [===>..........................] - ETA: 1s - loss: 0.1090 - accuracy: 0.9640\n",
      "Epoch 00091: saving model to checkpoints\\weights.91.hdf5\n",
      "1257/1708 [=====================>........] - ETA: 0s - loss: 0.1122 - accuracy: 0.9630\n",
      "Epoch 00091: saving model to checkpoints\\weights.91.hdf5\n",
      "1708/1708 [==============================] - 1s 722us/step - loss: 0.1127 - accuracy: 0.9628\n",
      "Epoch 92/100\n",
      " 486/1708 [=======>......................] - ETA: 0s - loss: 0.1090 - accuracy: 0.9644\n",
      "Epoch 00092: saving model to checkpoints\\weights.92.hdf5\n",
      "1557/1708 [==========================>...] - ETA: 0s - loss: 0.1103 - accuracy: 0.9635\n",
      "Epoch 00092: saving model to checkpoints\\weights.92.hdf5\n",
      "1708/1708 [==============================] - 1s 625us/step - loss: 0.1106 - accuracy: 0.9634\n",
      "Epoch 93/100\n",
      " 821/1708 [=============>................] - ETA: 0s - loss: 0.1135 - accuracy: 0.9627\n",
      "Epoch 00093: saving model to checkpoints\\weights.93.hdf5\n",
      "1708/1708 [==============================] - 1s 642us/step - loss: 0.1126 - accuracy: 0.9629\n",
      "Epoch 94/100\n",
      " 123/1708 [=>............................] - ETA: 1s - loss: 0.1161 - accuracy: 0.9624\n",
      "Epoch 00094: saving model to checkpoints\\weights.94.hdf5\n",
      "1126/1708 [==================>...........] - ETA: 0s - loss: 0.1151 - accuracy: 0.9623\n",
      "Epoch 00094: saving model to checkpoints\\weights.94.hdf5\n",
      "1708/1708 [==============================] - 1s 716us/step - loss: 0.1147 - accuracy: 0.9623\n",
      "Epoch 95/100\n",
      " 436/1708 [======>.......................] - ETA: 0s - loss: 0.1131 - accuracy: 0.9630\n",
      "Epoch 00095: saving model to checkpoints\\weights.95.hdf5\n",
      "1427/1708 [========================>.....] - ETA: 0s - loss: 0.1131 - accuracy: 0.9627\n",
      "Epoch 00095: saving model to checkpoints\\weights.95.hdf5\n",
      "1708/1708 [==============================] - 1s 654us/step - loss: 0.1129 - accuracy: 0.9628\n",
      "Epoch 96/100\n",
      " 698/1708 [===========>..................] - ETA: 0s - loss: 0.1170 - accuracy: 0.9598\n",
      "Epoch 00096: saving model to checkpoints\\weights.96.hdf5\n",
      "1708/1708 [==============================] - 1s 620us/step - loss: 0.1145 - accuracy: 0.9614\n",
      "Epoch 97/100\n",
      "   1/1708 [..............................] - ETA: 3s - loss: 0.0779 - accuracy: 0.9688\n",
      "Epoch 00097: saving model to checkpoints\\weights.97.hdf5\n",
      "1018/1708 [================>.............] - ETA: 0s - loss: 0.1132 - accuracy: 0.9625\n",
      "Epoch 00097: saving model to checkpoints\\weights.97.hdf5\n",
      "1708/1708 [==============================] - 1s 738us/step - loss: 0.1131 - accuracy: 0.9624\n",
      "Epoch 98/100\n",
      " 285/1708 [====>.........................] - ETA: 1s - loss: 0.1078 - accuracy: 0.9665\n",
      "Epoch 00098: saving model to checkpoints\\weights.98.hdf5\n",
      "1251/1708 [====================>.........] - ETA: 0s - loss: 0.1114 - accuracy: 0.9642\n",
      "Epoch 00098: saving model to checkpoints\\weights.98.hdf5\n",
      "1708/1708 [==============================] - 1s 669us/step - loss: 0.1119 - accuracy: 0.9638\n",
      "Epoch 99/100\n",
      " 583/1708 [=========>....................] - ETA: 0s - loss: 0.1109 - accuracy: 0.9636\n",
      "Epoch 00099: saving model to checkpoints\\weights.99.hdf5\n",
      "1597/1708 [===========================>..] - ETA: 0s - loss: 0.1111 - accuracy: 0.9635\n",
      "Epoch 00099: saving model to checkpoints\\weights.99.hdf5\n",
      "1708/1708 [==============================] - 1s 609us/step - loss: 0.1112 - accuracy: 0.9634\n",
      "Epoch 100/100\n",
      " 896/1708 [==============>...............] - ETA: 0s - loss: 0.1123 - accuracy: 0.9636\n",
      "Epoch 00100: saving model to checkpoints\\weights.100.hdf5\n",
      "1708/1708 [==============================] - 1s 595us/step - loss: 0.1126 - accuracy: 0.9632\n"
     ]
    }
   ],
   "source": [
    "# Compile and train the model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Create a callback that saves the model's weights every 5 epochs. Checkpoints will be saved every thousand samples tested (across all epochs).\n",
    "# Using the Keras ModelCheckpoint method\n",
    "cp_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    verbose=1,\n",
    "    save_weights_only=True,\n",
    "    save_freq=1000)\n",
    "\n",
    "# Train the model\n",
    "fit_model = nn.fit(X_train_scaled, y_train, epochs=100, callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "570/570 - 0s - loss: 0.1157 - accuracy: 0.9631\n",
      "Loss: 0.11565914005041122, Accuracy: 96.31093740463257 %\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy*100} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hierarchical Data Format file, HDF5. Using the Keras Sequential model's save method to export the model.\n",
    "# Export our model to HDF5 file\n",
    "nn.save(\"trained_food_desertUS.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_train= nn.predict(X_train)\n",
    "predictions_test= nn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54648, 1)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train_round = predictions_train.round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18216, 1)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.99975824],\n",
       "       [0.99978536],\n",
       "       [0.99984264],\n",
       "       ...,\n",
       "       [0.99981093],\n",
       "       [0.9996915 ],\n",
       "       [0.9997845 ]], dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test_round = predictions_test.round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54648,)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18216,)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54648, 1)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_reshape = y_train.values.reshape(54648,1)\n",
    "y_train_reshape.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18216, 1)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_reshape = y_test.values.reshape(18216,1)\n",
    "y_test_reshape.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [1],\n",
       "       ...,\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.99975824],\n",
       "       [0.99978536],\n",
       "       [0.99984264],\n",
       "       ...,\n",
       "       [0.99981093],\n",
       "       [0.9996915 ],\n",
       "       [0.9997845 ]], dtype=float32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_test= nn.predict_proba(X_test)\n",
    "prob_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52493"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_score= accuracy_score(y_train_reshape, predictions_train.round(), normalize = False)\n",
    "acc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52493"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_score= accuracy_score(y_train_reshape, pred_train_round, normalize = False)\n",
    "acc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17497"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_score= accuracy_score(y_test_reshape, pred_test_round, normalize = False)\n",
    "acc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    0  2155]\n",
      " [    0 52493]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix (y_train_reshape, pred_train_round))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    0   719]\n",
      " [    0 17497]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix (y_test_reshape, pred_test_round))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix (y_test_reshape, pred_test_round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                        normalize=False,\n",
    "                        title='Confusion matrix',\n",
    "                        cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_plot_labels = ['Below Poverty Level','Above Poverty Level']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[    0   719]\n",
      " [    0 17497]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(cm=cm, classes=cm_plot_labels, title='Confusion Matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the Training results from the full U.S. Trained weights on the Austin-Metro only data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NN Machine Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fit and transform the OneHotEncoder using the categorical variable list\n",
    "encodeAus_df = pd.DataFrame(enc.fit_transform(food_desert_Austin_df.Income.values.reshape(-1,1)))\n",
    "# encodeAus_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# labelencoder = LabelEncoder()\n",
    "# food_desert_Austin_df[\"CMatrix\"] = labelencoder.fit_transform(food_desert_Austin_df.Income)\n",
    "# food_desert_Austin_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    338\n",
       "0     12\n",
       "Name: Income, dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "food_desert_Austin_df[\"Income\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the preprocessed dataframe into our features and target arrays\n",
    "#  Remove Income target from features data\n",
    "y = encodeAus_df[1]\n",
    "X = food_desert_Austin_df.drop(columns=\"Income\").values\n",
    "\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 20)                180       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                210       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 401\n",
      "Trainable params: 401\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net. the number of input features and the hidden nodes for each layer.\n",
    "number_input_features = len(X_train[0])\n",
    "hidden_nodes_layer1 = 20\n",
    "hidden_nodes_layer2 = 10\n",
    "\n",
    "nn_new = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn_new.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\"))\n",
    "\n",
    "# Second hidden layer\n",
    "nn_new.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn_new.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn_new.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "9/9 [==============================] - 0s 748us/step - loss: 0.1149 - accuracy: 0.9683\n",
      "Epoch 2/50\n",
      "9/9 [==============================] - 0s 873us/step - loss: 0.1025 - accuracy: 0.9672\n",
      "Epoch 3/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0989 - accuracy: 0.9697\n",
      "Epoch 4/50\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.0927 - accuracy: 0.9718\n",
      "Epoch 5/50\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1051 - accuracy: 0.9598\n",
      "Epoch 6/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1111 - accuracy: 0.9643\n",
      "Epoch 7/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1137 - accuracy: 0.9625\n",
      "Epoch 8/50\n",
      "9/9 [==============================] - 0s 873us/step - loss: 0.1021 - accuracy: 0.9700\n",
      "Epoch 9/50\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.1093 - accuracy: 0.9619\n",
      "Epoch 10/50\n",
      "9/9 [==============================] - 0s 748us/step - loss: 0.1098 - accuracy: 0.9613\n",
      "Epoch 11/50\n",
      "9/9 [==============================] - 0s 748us/step - loss: 0.0906 - accuracy: 0.9682\n",
      "Epoch 12/50\n",
      "9/9 [==============================] - 0s 873us/step - loss: 0.1108 - accuracy: 0.9614\n",
      "Epoch 13/50\n",
      "9/9 [==============================] - 0s 748us/step - loss: 0.1146 - accuracy: 0.9521\n",
      "Epoch 14/50\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.0974 - accuracy: 0.9689\n",
      "Epoch 15/50\n",
      "9/9 [==============================] - 0s 624us/step - loss: 0.0998 - accuracy: 0.9691\n",
      "Epoch 16/50\n",
      "9/9 [==============================] - 0s 998us/step - loss: 0.0816 - accuracy: 0.9722\n",
      "Epoch 17/50\n",
      "9/9 [==============================] - 0s 873us/step - loss: 0.1248 - accuracy: 0.9615\n",
      "Epoch 18/50\n",
      "9/9 [==============================] - 0s 748us/step - loss: 0.1162 - accuracy: 0.9548\n",
      "Epoch 19/50\n",
      "9/9 [==============================] - 0s 873us/step - loss: 0.0916 - accuracy: 0.9681\n",
      "Epoch 20/50\n",
      "9/9 [==============================] - 0s 748us/step - loss: 0.0807 - accuracy: 0.9638\n",
      "Epoch 21/50\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.1149 - accuracy: 0.9559\n",
      "Epoch 22/50\n",
      "9/9 [==============================] - 0s 748us/step - loss: 0.0851 - accuracy: 0.9724\n",
      "Epoch 23/50\n",
      "9/9 [==============================] - 0s 873us/step - loss: 0.1026 - accuracy: 0.9601\n",
      "Epoch 24/50\n",
      "9/9 [==============================] - 0s 748us/step - loss: 0.0928 - accuracy: 0.9707\n",
      "Epoch 25/50\n",
      "9/9 [==============================] - 0s 748us/step - loss: 0.1050 - accuracy: 0.9639\n",
      "Epoch 26/50\n",
      "9/9 [==============================] - 0s 873us/step - loss: 0.0925 - accuracy: 0.9695\n",
      "Epoch 27/50\n",
      "9/9 [==============================] - 0s 623us/step - loss: 0.0814 - accuracy: 0.9666\n",
      "Epoch 28/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1051 - accuracy: 0.9657\n",
      "Epoch 29/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0898 - accuracy: 0.9689\n",
      "Epoch 30/50\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.0990 - accuracy: 0.9621\n",
      "Epoch 31/50\n",
      "9/9 [==============================] - 0s 873us/step - loss: 0.1377 - accuracy: 0.9405\n",
      "Epoch 32/50\n",
      "9/9 [==============================] - 0s 872us/step - loss: 0.0840 - accuracy: 0.9703\n",
      "Epoch 33/50\n",
      "9/9 [==============================] - 0s 873us/step - loss: 0.0758 - accuracy: 0.9680\n",
      "Epoch 34/50\n",
      "9/9 [==============================] - 0s 748us/step - loss: 0.0730 - accuracy: 0.9699\n",
      "Epoch 35/50\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.0853 - accuracy: 0.9675\n",
      "Epoch 36/50\n",
      "9/9 [==============================] - 0s 748us/step - loss: 0.1007 - accuracy: 0.9674\n",
      "Epoch 37/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0907 - accuracy: 0.9674\n",
      "Epoch 38/50\n",
      "9/9 [==============================] - 0s 873us/step - loss: 0.0859 - accuracy: 0.9680\n",
      "Epoch 39/50\n",
      "9/9 [==============================] - 0s 748us/step - loss: 0.0521 - accuracy: 0.9798\n",
      "Epoch 40/50\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.0893 - accuracy: 0.9603\n",
      "Epoch 41/50\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1103 - accuracy: 0.9477\n",
      "Epoch 42/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0837 - accuracy: 0.9677\n",
      "Epoch 43/50\n",
      "9/9 [==============================] - 0s 748us/step - loss: 0.0886 - accuracy: 0.9696\n",
      "Epoch 44/50\n",
      "9/9 [==============================] - 0s 873us/step - loss: 0.0873 - accuracy: 0.9610\n",
      "Epoch 45/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0712 - accuracy: 0.9728\n",
      "Epoch 46/50\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.0759 - accuracy: 0.9699\n",
      "Epoch 47/50\n",
      "9/9 [==============================] - 0s 748us/step - loss: 0.0767 - accuracy: 0.9727\n",
      "Epoch 48/50\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.1084 - accuracy: 0.9553\n",
      "Epoch 49/50\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0828 - accuracy: 0.9663\n",
      "Epoch 50/50\n",
      "9/9 [==============================] - 0s 748us/step - loss: 0.0778 - accuracy: 0.9633\n",
      "3/3 - 0s - loss: 0.1816 - accuracy: 0.9659\n",
      "Loss: 0.18161045014858246, Accuracy: 96.59090638160706 %\n"
     ]
    }
   ],
   "source": [
    "# Restore the model weights\n",
    "nn_new = tf.keras.models.load_model('trained_food_desertUS.h5')\n",
    "\n",
    "# Compile the model\n",
    "nn_new.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model\n",
    "fit_model = nn_new.fit(X_train_scaled,y_train,epochs=50)\n",
    "\n",
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn_new.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy*100} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hierarchical Data Format file, HDF5. Using the Keras Sequential model's save method to export the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the new model to HDF5 file\n",
    "nn_new.save(\"trained_food_desert_Austin.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying the saved h5 file to recreate, check, and test for performance. \n",
    "# Import the model to a new object\n",
    "nn_new_imported = tf.keras.models.load_model('trained_food_desert_Austin.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 - 0s - loss: 0.1816 - accuracy: 0.9659\n",
      "Loss: 0.18161045014858246, Accuracy: 96.59090638160706 %\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn_new.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy*100} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure connection and engine for AWS RDS with SQLAlchemy, and \n",
    "###   Writing to the PostgreSQL database: Module20_food_deserts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Configure connection and engine for AWS RDS with SQLAlchemy.\n",
    "# connection = psycopg2.connect(\n",
    "#     host = 'dataviz.c5qcqhh5xq62.us-east-2.rds.amazonaws.com',\n",
    "#     port = 5432,\n",
    "#     user = 'postgres',\n",
    "#     password = 'xxxxx',\n",
    "#     database= 'Module20_food_deserts'\n",
    "#     )\n",
    "# cursor=connection.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Creat engine for postgresql.\n",
    "# engine = create_engine('postgresql://postgres:Data1UT$@dataviz.c5qcqhh5xq62.us-east-2.rds.amazonaws.com/Module20_food_deserts')\n",
    "# con = engine.connect()\n",
    "\n",
    "# # LILATracts_1And10_aus_df\n",
    "# # food_austinMFI_df\n",
    "# # food_desert_Austin_df\n",
    "# # food_atlasMFI_df\n",
    "# # food_desertUS_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LILATracts_1And10_aus_df.to_sql('LILATracts_1And10_aus', engine, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# food_austinMFI_df.to_sql('food_austinMFI', engine, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# food_desert_Austin_df.to_sql('food_desert_Austin', engine, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# food_atlasMFI_df.to_sql('food_atlasMFI', engine, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# food_desertUS_df.to_sql('food_desertUS', engine, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Join two of the DataFrames\n",
    "# fooddesert_austin_censusshapes_df = fooddesert_austin_censustract_df.merge(census_tract_shapefiles_all_df, on=\"CensusTract\", how=\"inner\")\n",
    "# fooddesert_austin_censusshapes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # SQL LEFT JOIN \n",
    "# sql = \"SELECT \\\n",
    "#     fa.CensusTract, \\\n",
    "#     fa.LowIncomeTracts, \\\n",
    "#     fa.PovertyRate, \\\n",
    "#     fa.MedianFamilyIncome, \\\n",
    "#     fa.Income, \\\n",
    "#     li.LILATracts_1And10 \\\n",
    "# FROM food_austinMFI AS fa \\\n",
    "# LEFT JOIN LILATracts_1And10_aus AS li ON fa.CensusTract = li.CensusTract\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cursor.execute(sql)\n",
    "# myresult = cursor.fetchall()\n",
    "# for x in myresult:\n",
    "#    print(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
